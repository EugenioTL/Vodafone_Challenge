{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from sklearn import cross_validation, metrics\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# # Ignore warnings\n",
    "# import warnings\n",
    "# warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'train_rodolfo.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6cc3cb48adca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_data2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"testset.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_rodolfo.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_rodolfo.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\voda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\voda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\voda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\voda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\voda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'train_rodolfo.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Import the train set and test set\n",
    "train_data2 = pd.read_csv(\"trainset.csv\", delimiter=\",\")\n",
    "test_data2 = pd.read_csv(\"testset.csv\", delimiter=\",\")\n",
    "\n",
    "train = pd.read_csv(\"train_rodolfo.csv\", delimiter=\",\").fillna(0)\n",
    "test = pd.read_csv(\"test_rodolfo.csv\", delimiter=\",\").fillna(0)\n",
    "\n",
    "#train = train.dropna()\n",
    "# test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Product'\n",
    "IDcol = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test_results = pd.read_csv('test_results.csv')\n",
    "def modelfit2(alg, dtrain, dtest, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    # fit model on training data\n",
    "    model = alg\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dtrain[predictors], dtrain[target], test_size=0.33, random_state=7)\n",
    "    eval_set = [(X_test, y_test)]\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              early_stopping_rounds=early_stopping_rounds,\n",
    "              eval_metric=\"merror\",\n",
    "              eval_set=eval_set,\n",
    "              verbose=False)\n",
    "    \n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1_scor = f1_score(y_test, predictions, average='micro')  \n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    print(\"f1_micro: %.2f%%\" % (f1_scor * 100.0))\n",
    "    \n",
    "#     if useTrainCV:\n",
    "#         xgb_param = alg.get_xgb_params()\n",
    "#         xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "#         xgtest = xgb.DMatrix(dtest[predictors].values)\n",
    "#         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "#             metrics='merror',\n",
    "#                           early_stopping_rounds=early_stopping_rounds)\n",
    "#         alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "#     #Fit the algorithm on the data\n",
    "#     alg.fit(dtrain[predictors], dtrain['Product'],eval_metric='auc')\n",
    "        \n",
    "#     #Predict training set:\n",
    "#     dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "#     dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "#     #Print model report:\n",
    "#     print(\"\\nModel Report\")\n",
    "#     print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Product'].values, dtrain_predictions))\n",
    "#     #print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Product'], dtrain_predprob))\n",
    "    \n",
    "# #     Predict on testing data:\n",
    "    dtest['predprob'] = alg.predict_proba(dtest[predictors])[:,1]\n",
    "    results = test_results.merge(dtest[['ID','predprob']], on='ID')\n",
    "    #print(dtest[['ID','predprob']])\n",
    "#     #print('AUC Score (Test): %f' % metrics.roc_auc_score(results['Product'], results['predprob']))\n",
    "        \n",
    "    #feat_imp = pd.Series(model.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')\n",
    "\n",
    "    plot_importance(model)\n",
    "    plt.show()\n",
    "    print(\"Model: \" + str(model))\n",
    "    thresholds = alg.feature_importances_\n",
    "    print(\"Feature_Importances: \")\n",
    "    print(dtrain.columns[thresholds.argsort()[-10:][::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='merror', early_stopping_rounds=early_stopping_rounds, \n",
    "                          verbose_eval=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Product'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    #dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "\n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Product'].values, dtrain_predictions))\n",
    "    print(\"F1_score : %f\" % metrics.f1_score(dtrain['Product'], dtrain_predictions, average='micro'))\n",
    "                    \n",
    "#     feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')\n",
    "    plot_importance(alg)\n",
    "    plt.show()\n",
    "    thresholds = alg.feature_importances_\n",
    "    print(\"Feature_Importances: \")\n",
    "    print(dtrain.columns[thresholds.argsort()[-10:][::-1]])\n",
    "    print(\"Model: \" + str(alg.get_xgb_params()))\n",
    "    print(\"n_estimator: \" + str(cvresult.shape[0]))\n",
    "    return cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(model, nfeatures = 10):\n",
    "    model.fit()\n",
    "    thresholds = model.feature_importances_\n",
    "    \n",
    "    return train.column[thresholds.argsort()[-nfeatures:][::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1- Find the number of estimators for a high learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb0 = XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=4)\n",
    "# print(train[predictors].values)\n",
    "modelfit(xgb0, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "n_estimators = 1000\n",
    "max_depth = 5\n",
    "min_child_weight = 1\n",
    "gamma = 0\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "reg_alpha = 0.005\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective='multi:softprob',\n",
    "        num_class=4,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "n_estimators = modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample,\n",
    "                                        colsample_bytree=colsample_bytree, objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1, seed=27), \n",
    "                       param_grid = param_test1, scoring='f1_micro',n_jobs=4,iid=False, cv=cv,verbose=1)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = gsearch1.best_params_['max_depth']\n",
    "min_child_weight = gsearch1.best_params_['min_child_weight']\n",
    "max_depth,min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test2 = {\n",
    "    'max_depth':[max_depth-1,max_depth,max_depth+1],\n",
    "    'min_child_weight':[min_child_weight-1,min_child_weight,min_child_weight+1]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                        objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test2, scoring='f1_micro',n_jobs=4,iid=False, cv=cv, verbose=1)\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = gsearch2.best_params_['max_depth']\n",
    "min_child_weight = gsearch2.best_params_['min_child_weight']\n",
    "max_depth,min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features#Grid se \n",
    "#Choose all predictors except target & IDcols\n",
    "param_test2b = {\n",
    "    'min_child_weight':[min_child_weight,min_child_weight+2,min_child_weight+4,min_child_weight+6]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                        objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test2b, scoring='f1_micro',n_jobs=4,iid=False, cv=cv, verbose=1)\n",
    "gsearch2b.fit(train[predictors],train[target])\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_weight = gsearch2b.best_params_['min_child_weight']\n",
    "min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test3 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                        objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test3, scoring='f1_micro',n_jobs=4,iid=False, cv=cv, verbose=1)\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = gsearch3.best_params_['gamma']\n",
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb2 = XGBClassifier(\n",
    "        learning_rate =learning_rate,\n",
    "        n_estimators=1000,\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective='multi:softprob', \n",
    "        num_class=4,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "n_estimators = modelfit(xgb2, train, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                        objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test4, scoring='f1_micro',n_jobs=4,iid=False, cv=cv, verbose=1)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = gsearch4.best_params_['subsample']\n",
    "colsample_bytree = gsearch4.best_params_['colsample_bytree']\n",
    "subsample,colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test5 = {\n",
    "    'subsample':[i/100.0 for i in range(int(subsample*100-5),int(subsample*100+5),5)],\n",
    "    'colsample_bytree':[i/100.0 for i in range(int(colsample_bytree*100-5),int(colsample_bytree*100+5),5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                        objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test5, scoring='f1_micro',n_jobs=4,iid=False, cv=cv, verbose=1)\n",
    "gsearch5.fit(train[predictors],train[target])\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = gsearch5.best_params_['subsample']\n",
    "colsample_bytree = gsearch5.best_params_['colsample_bytree']\n",
    "subsample,colsample_bytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test6 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                        objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test6, scoring='f1_micro',n_jobs=4,iid=False, cv=cv, verbose=1)\n",
    "gsearch6.fit(train[predictors],train[target])\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_alpha = gsearch6.best_params_['reg_alpha']\n",
    "reg_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test7 = {\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                        objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test7, scoring='f1_micro',n_jobs=4,iid=False, cv=cv,verbose=1)\n",
    "gsearch7.fit(train[predictors],train[target])\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_alpha = gsearch7.best_params_['reg_alpha']\n",
    "reg_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    "        learning_rate =learning_rate,\n",
    "        n_estimators=1000,\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        objective='multi:softprob', \n",
    "        num_class=4,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "n_estimators = modelfit(xgb3, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=209,\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        objective='multi:softprob', \n",
    "        num_class=4,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "n_estimators = modelfit(xgb4, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test8 = {\n",
    "    #learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators' : [50, 100, 150, 200, 300]\n",
    "}\n",
    "gsearch8 = GridSearchCV(estimator = XGBClassifier( learning_rate =learning_rate, n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_child_weight=min_child_weight, gamma=gamma, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                        objective='multi:softprob', num_class=4, nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test8, scoring='f1_micro',n_jobs=4,iid=False, cv=cv,verbose=1)\n",
    "gsearch8.fit(train[predictors],train[target])\n",
    "gsearch8.grid_scores_, gsearch8.best_params_, gsearch8.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[predictors].shape,train[target].shape,test[predictors].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ['ZipCode', 'CustomerExpatriate', 'MonthlySMSTrafficCount',\n",
    "       'DeviceFlagSmartphone', 'DeviceFlag4G', 'DataArpu', 'Region',\n",
    "       'MonthlyVoiceTrafficCount', 'Instant-Messaging-Applications',\n",
    "       'Unclassified']\n",
    "train[pred].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        objective='multi:softprob', \n",
    "        num_class=4,\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "n_estimators = modelfit(xgb4, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(train[predictors], train[target], test_size=0.33, random_state=7)\n",
    "# eval_set = [(X_test, y_test)]\n",
    "xgb4.fit(train[pred],\n",
    "      train[target],\n",
    "      eval_metric=\"merror\",\n",
    "      verbose=True)\n",
    "\n",
    "y_pred_new_data = xgb4.predict(test[pred])\n",
    "predictions = [round(value) for value in y_pred_new_data]\n",
    "\n",
    "print(\"F1 score on unseen data: %.3f%%\" % (f1_score(train[target][0:3190], y_pred_new_data, average='micro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Product': y_pred_new_data}).describe(),pd.DataFrame({'Product': predictions}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame({'Product': y_pred_new_data})\n",
    "submit = test['ID']\n",
    "submit = pd.DataFrame({'ID': submit})\n",
    "\n",
    "pred = y\n",
    "pred = pd.DataFrame({'Product': y_pred_new_data})\n",
    "\n",
    "product = []\n",
    "product = pred.Product\n",
    "product.replace({ \n",
    "    int(0) : 'Non-Customer', \n",
    "    int(1) : 'V-Bag', \n",
    "    int(2) : 'V-Pet', \n",
    "    int(3) : 'V-Auto'},\n",
    "    inplace=True)\n",
    "\n",
    "submit = submit.join(product)\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.Product.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('resultxgb.csv', index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors = [x for x in train.columns if x not in [target]]\n",
    "# # split data into X and y\n",
    "# X = train[predictors]\n",
    "# Y = train[target]\n",
    "# # split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# # fit model on all training data\n",
    "# model = XGBClassifier(\n",
    "#         objective='multi:softprob', \n",
    "#         num_class=4)\n",
    "# model.fit(X_train, y_train)\n",
    "# # make predictions for test data and evaluate\n",
    "# y_pred = model.predict(X_test)\n",
    "# predictions = [round(value) for value in y_pred]\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# # Fit model using each importance as a threshold\n",
    "# thresholds = sort(model.feature_importances_)\n",
    "# for thresh in thresholds:\n",
    "#     # select features using threshold\n",
    "#     selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "#     select_X_train = selection.transform(X_train)\n",
    "#     # train model\n",
    "#     selection_model = XGBClassifier(objective='multi:softprob', \n",
    "#         num_class=4)\n",
    "#     selection_model.fit(select_X_train, y_train)\n",
    "#     # eval model\n",
    "#     select_X_test = selection.transform(X_test)\n",
    "#     y_pred = selection_model.predict(select_X_test)\n",
    "#     predictions = [round(value) for value in y_pred]\n",
    "#     accuracy = accuracy_score(y_test, predictions)\n",
    "#     print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = model.feature_importances_\n",
    "# thresholds\n",
    "\n",
    "# thresholds.argsort()[-10:][::-1]\n",
    "# train.columns[thresholds.argsort()[-10:][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
