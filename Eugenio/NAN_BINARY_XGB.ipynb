{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vodafone challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Import evaluation libraries\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Import model libraries\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = 202\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import, clean and sort the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train set and test set\n",
    "train_data = pd.read_csv(\"nan_final_train.csv\", delimiter=\",\")\n",
    "test_data = pd.read_csv(\"nan_final_test.csv\", delimiter=\",\")\n",
    "\n",
    "# Drop the ID column\n",
    "train_data = train_data.drop('ID', axis=1)\n",
    "\n",
    "# Sort the dataset\n",
    "train_data = train_data.iloc[np.random.permutation(len(train_data))]\n",
    "train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the best features with SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best features for binary and multiclass tasks\n",
    "\n",
    "array = np.asarray(train_data.dropna())\n",
    "\n",
    "# X,Y are the splits between features and labels used to evaluate SelectKBest\n",
    "X = array[:,0:train_data.shape[1]-1]\n",
    "X = np.asarray(X)\n",
    "Y = array[:,train_data.shape[1]-1]\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "# Evaluate the features with a chi2 test by using SelectKBest\n",
    "bin_feature_number = 'all'\n",
    "bin_chi2_test = SelectKBest(score_func=chi2, k=bin_feature_number)\n",
    "fit = bin_chi2_test.fit(X,Y)\n",
    "bin_feat = train_data.columns[bin_chi2_test.get_support(indices=True)]\n",
    "\n",
    "v_feature_number = 'all'\n",
    "v_chi2_test = SelectKBest(score_func=chi2, k=v_feature_number)\n",
    "fit = v_chi2_test.fit(X,Y)\n",
    "v_feat = train_data.columns[v_chi2_test.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler_Column(column):\n",
    "    return (column - column.min())/(column.max()-column.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_split(data):   \n",
    "    features = data[bin_feat]\n",
    "    labels = data['Product']\n",
    "    # Data normalization\n",
    "    data['Region'] = MinMaxScaler_Column(data['Region'])\n",
    "    data['Province'] = MinMaxScaler_Column(data['Province'])\n",
    "    data['CustomerAge'] = MinMaxScaler_Column(data['CustomerAge'])\n",
    "    data['ZipCode'] = MinMaxScaler_Column(data['ZipCode'])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(features, labels, val_samples, test_samples):\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels =np.asarray(labels)\n",
    "    \n",
    "    X_test = features[0:test_samples]\n",
    "    y_test = labels[0:test_samples]\n",
    "\n",
    "    X_val = features[test_samples:test_samples + val_samples]\n",
    "    y_val = labels[test_samples:test_samples + val_samples]\n",
    "\n",
    "    X_train = features[test_samples + val_samples:]\n",
    "    y_train = labels[test_samples + val_samples:]\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feat, train_label are the splits of train_data between features and labels\n",
    "train_feat, train_label = features_labels_split(train_data.dropna())\n",
    "\n",
    "train_feat = train_feat.reset_index(drop=True)\n",
    "train_label = train_label.reset_index(drop=True)\n",
    "\n",
    "# bin_train_label is the same of train_label but BINARY\n",
    "bin_train_label = []\n",
    " \n",
    "for i in range(0, len(train_label)):\n",
    "    if(train_label[i] == 0):\n",
    "        bin_train_label.append(0)\n",
    "    else:\n",
    "        bin_train_label.append(1)\n",
    "bin_train_label = np.asarray(bin_train_label)\n",
    "\n",
    "\n",
    "num_val_samples = 0\n",
    "num_test_samples = 950\n",
    "# bin_X_train, bin_X_test, bin_X_val, bin_y_train, bin_y_test, bin_y_val are the splits of train_feat and bin_train_label\n",
    "bin_X_train, bin_X_test, bin_X_val, bin_y_train, bin_y_test, bin_y_val = train_test_validation_split(train_feat, bin_train_label, num_val_samples, num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6160,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
