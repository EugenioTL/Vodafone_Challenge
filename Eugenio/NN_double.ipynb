{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Import evaluation libraries\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Import model libraries\n",
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = 202\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train set and test set\n",
    "train_data = pd.read_csv(\"final_train.csv\", delimiter=\",\")\n",
    "test_data = pd.read_csv(\"final_test.csv\", delimiter=\",\")\n",
    "\n",
    "# Drop the ID column\n",
    "train_data = train_data.drop('ID', axis=1)\n",
    "\n",
    "# Sort the dataset\n",
    "train_data = train_data.iloc[np.random.permutation(len(train_data))]\n",
    "train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best features for binary and multiclass tasks\n",
    "\n",
    "array = np.asarray(train_data)\n",
    "\n",
    "# X,Y are the splits between features and labels used to evaluate SelectKBest\n",
    "X = array[:,0:train_data.shape[1]-1]\n",
    "X = np.asarray(X)\n",
    "Y = array[:,train_data.shape[1]-1]\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "# Evaluate the features with a chi2 test by using SelectKBest\n",
    "bin_chi2_test = SelectKBest(score_func=chi2, k=28)\n",
    "fit = bin_chi2_test.fit(X,Y)\n",
    "bin_feat = train_data.columns[bin_chi2_test.get_support(indices=True)]\n",
    "\n",
    "v_chi2_test = SelectKBest(score_func=chi2, k=27)\n",
    "fit = v_chi2_test.fit(X,Y)\n",
    "v_feat = train_data.columns[v_chi2_test.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_split(data):\n",
    "    \n",
    "    features = data[bin_feat]\n",
    "    labels = data['Product']\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(features):\n",
    "\n",
    "    scaler = MinMaxScaler().fit(features)\n",
    "    features = scaler.transform(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(features, labels, val_samples, test_samples):\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    features = standardize_features(features)\n",
    "    labels =np.asarray(labels)\n",
    "    \n",
    "    X_test = features[0:test_samples]\n",
    "    y_test = labels[0:test_samples]\n",
    "\n",
    "    X_val = features[test_samples:test_samples + val_samples]\n",
    "    y_val = labels[test_samples:test_samples + val_samples]\n",
    "\n",
    "    X_train = features[test_samples + val_samples:]\n",
    "    y_train = labels[test_samples + val_samples:]\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9567, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feat, train_label are the splits of train_data between features and labels\n",
    "train_feat, train_label = features_labels_split(train_data)\n",
    "\n",
    "# bin_train_label is the same of train_label but BINARY\n",
    "bin_train_label = []\n",
    " \n",
    "for i in range(0, len(train_label)):\n",
    "    if(train_label[i] == 0):\n",
    "        bin_train_label.append(0)\n",
    "    else:\n",
    "        bin_train_label.append(1)\n",
    "bin_train_label = np.asarray(bin_train_label)\n",
    "#print(train_label)\n",
    "#print(bin_train_label)\n",
    "num_val_samples = 950\n",
    "num_test_samples = 950\n",
    "\n",
    "# bin_X_train, bin_X_test, bin_X_val, bin_y_train, bin_y_test, bin_y_val are the splits of train_feat and bin_train_label\n",
    "bin_X_train, bin_X_test, bin_X_val, bin_y_train, bin_y_test, bin_y_val = train_test_validation_split(train_feat, bin_train_label, num_val_samples, num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7667, 28)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 64\n",
    "dropout = 0.5\n",
    "batch_size = 64         \n",
    "epochs = 5000\n",
    "\n",
    "output_activation_function = 'sigmoid'\n",
    "activation_function = 'relu'\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "learning_rate = 0.001\n",
    "optimizer= Adam(learning_rate)\n",
    "\n",
    "def build_model(inputs, output_size, neurons, activ_func=activation_function,\n",
    "                dropout = dropout, loss=loss, optimizer=optimizer):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_shape=(bin_X_train.shape[1],)))\n",
    "    model.add(Activation(activation_function))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size, activation=output_activation_function))    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise model architecture\n",
    "output_size = 1\n",
    "eth_model = build_model(bin_X_train, output_size=output_size, neurons=neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7667 samples, validate on 950 samples\n",
      "Epoch 1/5000\n",
      "7667/7667 [==============================] - 8s 1ms/step - loss: 0.6653 - f1: 0.4741 - val_loss: 0.6304 - val_f1: 0.5341\n",
      "Epoch 2/5000\n",
      "7667/7667 [==============================] - 3s 344us/step - loss: 0.6366 - f1: 0.5599 - val_loss: 0.6154 - val_f1: 0.5661\n",
      "Epoch 3/5000\n",
      "7667/7667 [==============================] - 3s 334us/step - loss: 0.6296 - f1: 0.5797 - val_loss: 0.6095 - val_f1: 0.5731\n",
      "Epoch 4/5000\n",
      "7667/7667 [==============================] - 3s 356us/step - loss: 0.6222 - f1: 0.5893 - val_loss: 0.6031 - val_f1: 0.5775\n",
      "Epoch 5/5000\n",
      "7667/7667 [==============================] - 2s 308us/step - loss: 0.6161 - f1: 0.5901 - val_loss: 0.5994 - val_f1: 0.5912\n",
      "Epoch 6/5000\n",
      "7667/7667 [==============================] - 3s 378us/step - loss: 0.6133 - f1: 0.5979 - val_loss: 0.5960 - val_f1: 0.5874\n",
      "Epoch 7/5000\n",
      "7667/7667 [==============================] - 3s 382us/step - loss: 0.6118 - f1: 0.5949 - val_loss: 0.5936 - val_f1: 0.5846\n",
      "Epoch 8/5000\n",
      "7667/7667 [==============================] - 3s 347us/step - loss: 0.6067 - f1: 0.6067 - val_loss: 0.5908 - val_f1: 0.5883\n",
      "Epoch 9/5000\n",
      "7667/7667 [==============================] - 3s 333us/step - loss: 0.6048 - f1: 0.6037 - val_loss: 0.5884 - val_f1: 0.5888\n",
      "Epoch 10/5000\n",
      "7667/7667 [==============================] - 3s 327us/step - loss: 0.6026 - f1: 0.6073 - val_loss: 0.5867 - val_f1: 0.5865\n",
      "Epoch 11/5000\n",
      "7667/7667 [==============================] - 3s 406us/step - loss: 0.6020 - f1: 0.6038 - val_loss: 0.5858 - val_f1: 0.6045\n",
      "Epoch 12/5000\n",
      "7667/7667 [==============================] - 3s 406us/step - loss: 0.5995 - f1: 0.6098 - val_loss: 0.5831 - val_f1: 0.5981\n",
      "Epoch 13/5000\n",
      "7667/7667 [==============================] - 3s 395us/step - loss: 0.5957 - f1: 0.6148 - val_loss: 0.5807 - val_f1: 0.6029\n",
      "Epoch 14/5000\n",
      "7667/7667 [==============================] - 3s 348us/step - loss: 0.5944 - f1: 0.6189 - val_loss: 0.5799 - val_f1: 0.6018\n",
      "Epoch 15/5000\n",
      "7667/7667 [==============================] - 3s 341us/step - loss: 0.5971 - f1: 0.6113 - val_loss: 0.5810 - val_f1: 0.5999\n",
      "Epoch 16/5000\n",
      "7667/7667 [==============================] - 3s 362us/step - loss: 0.5949 - f1: 0.6166 - val_loss: 0.5802 - val_f1: 0.6042\n",
      "Epoch 17/5000\n",
      "7667/7667 [==============================] - 2s 292us/step - loss: 0.5925 - f1: 0.6193 - val_loss: 0.5777 - val_f1: 0.6111\n",
      "Epoch 18/5000\n",
      "7667/7667 [==============================] - 2s 302us/step - loss: 0.5878 - f1: 0.6183 - val_loss: 0.5769 - val_f1: 0.6087\n",
      "Epoch 19/5000\n",
      "7667/7667 [==============================] - 2s 250us/step - loss: 0.5905 - f1: 0.6264 - val_loss: 0.5777 - val_f1: 0.6071\n",
      "Epoch 20/5000\n",
      "7667/7667 [==============================] - 2s 242us/step - loss: 0.5894 - f1: 0.6179 - val_loss: 0.5782 - val_f1: 0.6124\n",
      "Epoch 21/5000\n",
      "7667/7667 [==============================] - 2s 232us/step - loss: 0.5888 - f1: 0.6184 - val_loss: 0.5764 - val_f1: 0.6028\n",
      "Epoch 22/5000\n",
      "7667/7667 [==============================] - 2s 218us/step - loss: 0.5887 - f1: 0.6216 - val_loss: 0.5763 - val_f1: 0.6106\n",
      "Epoch 23/5000\n",
      "7667/7667 [==============================] - 2s 224us/step - loss: 0.5840 - f1: 0.6268 - val_loss: 0.5758 - val_f1: 0.6094\n",
      "Epoch 24/5000\n",
      "7667/7667 [==============================] - 1s 194us/step - loss: 0.5859 - f1: 0.6254 - val_loss: 0.5763 - val_f1: 0.6049\n",
      "Epoch 25/5000\n",
      "7667/7667 [==============================] - 1s 184us/step - loss: 0.5858 - f1: 0.6279 - val_loss: 0.5761 - val_f1: 0.6015\n",
      "Epoch 26/5000\n",
      "7667/7667 [==============================] - 1s 175us/step - loss: 0.5864 - f1: 0.6224 - val_loss: 0.5758 - val_f1: 0.6065\n",
      "Epoch 27/5000\n",
      "7667/7667 [==============================] - 1s 174us/step - loss: 0.5837 - f1: 0.6268 - val_loss: 0.5756 - val_f1: 0.6085\n",
      "Epoch 28/5000\n",
      "7667/7667 [==============================] - 1s 183us/step - loss: 0.5822 - f1: 0.6252 - val_loss: 0.5757 - val_f1: 0.6129\n",
      "Epoch 29/5000\n",
      "7667/7667 [==============================] - 1s 185us/step - loss: 0.5828 - f1: 0.6221 - val_loss: 0.5746 - val_f1: 0.6137\n",
      "Epoch 30/5000\n",
      "7667/7667 [==============================] - 1s 161us/step - loss: 0.5808 - f1: 0.6246 - val_loss: 0.5765 - val_f1: 0.6088\n",
      "Epoch 31/5000\n",
      "7667/7667 [==============================] - 1s 155us/step - loss: 0.5848 - f1: 0.6255 - val_loss: 0.5773 - val_f1: 0.6090\n",
      "Epoch 32/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5821 - f1: 0.6282 - val_loss: 0.5774 - val_f1: 0.6146\n",
      "Epoch 33/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5805 - f1: 0.6288 - val_loss: 0.5777 - val_f1: 0.6080\n",
      "Epoch 34/5000\n",
      "7667/7667 [==============================] - 1s 160us/step - loss: 0.5834 - f1: 0.6237 - val_loss: 0.5777 - val_f1: 0.6115\n",
      "Epoch 35/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5786 - f1: 0.6378 - val_loss: 0.5774 - val_f1: 0.6163\n",
      "Epoch 36/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5799 - f1: 0.6314 - val_loss: 0.5774 - val_f1: 0.6080\n",
      "Epoch 37/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5796 - f1: 0.6299 - val_loss: 0.5781 - val_f1: 0.6179\n",
      "Epoch 38/5000\n",
      "7667/7667 [==============================] - 1s 156us/step - loss: 0.5824 - f1: 0.6274 - val_loss: 0.5785 - val_f1: 0.6102\n",
      "Epoch 39/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5773 - f1: 0.6289 - val_loss: 0.5774 - val_f1: 0.6150\n",
      "Epoch 40/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5780 - f1: 0.6333 - val_loss: 0.5768 - val_f1: 0.6180\n",
      "Epoch 41/5000\n",
      "7667/7667 [==============================] - 1s 159us/step - loss: 0.5774 - f1: 0.6323 - val_loss: 0.5787 - val_f1: 0.6132\n",
      "Epoch 42/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5800 - f1: 0.6309 - val_loss: 0.5778 - val_f1: 0.6102\n",
      "Epoch 43/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5764 - f1: 0.6333 - val_loss: 0.5786 - val_f1: 0.6158\n",
      "Epoch 44/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5743 - f1: 0.6356 - val_loss: 0.5778 - val_f1: 0.6192\n",
      "Epoch 45/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5772 - f1: 0.6301 - val_loss: 0.5792 - val_f1: 0.6173\n",
      "Epoch 46/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5753 - f1: 0.6280 - val_loss: 0.5790 - val_f1: 0.6127\n",
      "Epoch 47/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5751 - f1: 0.6345 - val_loss: 0.5793 - val_f1: 0.6123\n",
      "Epoch 48/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5749 - f1: 0.6352 - val_loss: 0.5786 - val_f1: 0.6200\n",
      "Epoch 49/5000\n",
      "7667/7667 [==============================] - ETA: 0s - loss: 0.5764 - f1: 0.63 - 1s 144us/step - loss: 0.5753 - f1: 0.6331 - val_loss: 0.5783 - val_f1: 0.6201\n",
      "Epoch 50/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5764 - f1: 0.6287 - val_loss: 0.5787 - val_f1: 0.6201\n",
      "Epoch 51/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5744 - f1: 0.6340 - val_loss: 0.5780 - val_f1: 0.6139\n",
      "Epoch 52/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5754 - f1: 0.6308 - val_loss: 0.5795 - val_f1: 0.6173\n",
      "Epoch 53/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5759 - f1: 0.6300 - val_loss: 0.5787 - val_f1: 0.6230\n",
      "Epoch 54/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5727 - f1: 0.6389 - val_loss: 0.5784 - val_f1: 0.6002\n",
      "Epoch 55/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5704 - f1: 0.6330 - val_loss: 0.5786 - val_f1: 0.6191\n",
      "Epoch 56/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5743 - f1: 0.6382 - val_loss: 0.5794 - val_f1: 0.6171\n",
      "Epoch 57/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5720 - f1: 0.6341 - val_loss: 0.5794 - val_f1: 0.6135\n",
      "Epoch 58/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5696 - f1: 0.6349 - val_loss: 0.5803 - val_f1: 0.6041\n",
      "Epoch 59/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5767 - f1: 0.6350 - val_loss: 0.5805 - val_f1: 0.6144\n",
      "Epoch 60/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5706 - f1: 0.6404 - val_loss: 0.5801 - val_f1: 0.6120\n",
      "Epoch 61/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5718 - f1: 0.6386 - val_loss: 0.5801 - val_f1: 0.6126\n",
      "Epoch 62/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5700 - f1: 0.6375 - val_loss: 0.5802 - val_f1: 0.6164\n",
      "Epoch 63/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5703 - f1: 0.6342 - val_loss: 0.5799 - val_f1: 0.6239\n",
      "Epoch 64/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5707 - f1: 0.6394 - val_loss: 0.5798 - val_f1: 0.6217\n",
      "Epoch 65/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5718 - f1: 0.6346 - val_loss: 0.5797 - val_f1: 0.6180\n",
      "Epoch 66/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5719 - f1: 0.6366 - val_loss: 0.5798 - val_f1: 0.6100\n",
      "Epoch 67/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5699 - f1: 0.6338 - val_loss: 0.5797 - val_f1: 0.6139\n",
      "Epoch 68/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5676 - f1: 0.6372 - val_loss: 0.5804 - val_f1: 0.6204\n",
      "Epoch 69/5000\n",
      "7667/7667 [==============================] - 1s 155us/step - loss: 0.5724 - f1: 0.6456 - val_loss: 0.5809 - val_f1: 0.6125\n",
      "Epoch 70/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5716 - f1: 0.6407 - val_loss: 0.5800 - val_f1: 0.6172\n",
      "Epoch 71/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5669 - f1: 0.6424 - val_loss: 0.5811 - val_f1: 0.6259\n",
      "Epoch 72/5000\n",
      "7667/7667 [==============================] - 1s 152us/step - loss: 0.5690 - f1: 0.6453 - val_loss: 0.5810 - val_f1: 0.6154\n",
      "Epoch 73/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5661 - f1: 0.6446 - val_loss: 0.5825 - val_f1: 0.6156\n",
      "Epoch 74/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5696 - f1: 0.6392 - val_loss: 0.5817 - val_f1: 0.6213\n",
      "Epoch 75/5000\n",
      "7667/7667 [==============================] - 1s 154us/step - loss: 0.5655 - f1: 0.6430 - val_loss: 0.5813 - val_f1: 0.6135\n",
      "Epoch 76/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5678 - f1: 0.6462 - val_loss: 0.5834 - val_f1: 0.6140\n",
      "Epoch 77/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5686 - f1: 0.6400 - val_loss: 0.5817 - val_f1: 0.6209\n",
      "Epoch 78/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5666 - f1: 0.6442 - val_loss: 0.5821 - val_f1: 0.6185\n",
      "Epoch 79/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5670 - f1: 0.6449 - val_loss: 0.5830 - val_f1: 0.6177\n",
      "Epoch 80/5000\n",
      "7667/7667 [==============================] - 1s 158us/step - loss: 0.5662 - f1: 0.6440 - val_loss: 0.5824 - val_f1: 0.6197\n",
      "Epoch 81/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5650 - f1: 0.6417 - val_loss: 0.5827 - val_f1: 0.6140\n",
      "Epoch 82/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5668 - f1: 0.6403 - val_loss: 0.5828 - val_f1: 0.6224\n",
      "Epoch 83/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5682 - f1: 0.6464 - val_loss: 0.5823 - val_f1: 0.6311\n",
      "Epoch 84/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5676 - f1: 0.6460 - val_loss: 0.5834 - val_f1: 0.6154\n",
      "Epoch 85/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5661 - f1: 0.6457 - val_loss: 0.5840 - val_f1: 0.6199\n",
      "Epoch 86/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5643 - f1: 0.6412 - val_loss: 0.5837 - val_f1: 0.6158\n",
      "Epoch 87/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5652 - f1: 0.6452 - val_loss: 0.5833 - val_f1: 0.6247\n",
      "Epoch 88/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5635 - f1: 0.6454 - val_loss: 0.5825 - val_f1: 0.6314\n",
      "Epoch 89/5000\n",
      "7667/7667 [==============================] - 1s 152us/step - loss: 0.5670 - f1: 0.6420 - val_loss: 0.5823 - val_f1: 0.6159\n",
      "Epoch 90/5000\n",
      "7667/7667 [==============================] - 1s 159us/step - loss: 0.5635 - f1: 0.6468 - val_loss: 0.5835 - val_f1: 0.6259\n",
      "Epoch 91/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5633 - f1: 0.6404 - val_loss: 0.5843 - val_f1: 0.6207\n",
      "Epoch 92/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5642 - f1: 0.6414 - val_loss: 0.5850 - val_f1: 0.6287\n",
      "Epoch 93/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5658 - f1: 0.6478 - val_loss: 0.5850 - val_f1: 0.6252\n",
      "Epoch 94/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5629 - f1: 0.6455 - val_loss: 0.5836 - val_f1: 0.6156\n",
      "Epoch 95/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5649 - f1: 0.6451 - val_loss: 0.5859 - val_f1: 0.6243\n",
      "Epoch 96/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5616 - f1: 0.6420 - val_loss: 0.5854 - val_f1: 0.6270\n",
      "Epoch 97/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5642 - f1: 0.6537 - val_loss: 0.5858 - val_f1: 0.6321\n",
      "Epoch 98/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5594 - f1: 0.6491 - val_loss: 0.5855 - val_f1: 0.6132\n",
      "Epoch 99/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5607 - f1: 0.6549 - val_loss: 0.5855 - val_f1: 0.6256\n",
      "Epoch 100/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5639 - f1: 0.6503 - val_loss: 0.5857 - val_f1: 0.6192\n",
      "Epoch 101/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5608 - f1: 0.6482 - val_loss: 0.5852 - val_f1: 0.6257\n",
      "Epoch 102/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5593 - f1: 0.6527 - val_loss: 0.5857 - val_f1: 0.6268\n",
      "Epoch 103/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5617 - f1: 0.6476 - val_loss: 0.5861 - val_f1: 0.6260\n",
      "Epoch 104/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5621 - f1: 0.6499 - val_loss: 0.5859 - val_f1: 0.6211\n",
      "Epoch 105/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5584 - f1: 0.6468 - val_loss: 0.5864 - val_f1: 0.6281\n",
      "Epoch 106/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5644 - f1: 0.6470 - val_loss: 0.5862 - val_f1: 0.6126\n",
      "Epoch 107/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5583 - f1: 0.6516 - val_loss: 0.5868 - val_f1: 0.6297\n",
      "Epoch 108/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5611 - f1: 0.6516 - val_loss: 0.5856 - val_f1: 0.6251\n",
      "Epoch 109/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5550 - f1: 0.6588 - val_loss: 0.5859 - val_f1: 0.6257\n",
      "Epoch 110/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5588 - f1: 0.6525 - val_loss: 0.5854 - val_f1: 0.6229\n",
      "Epoch 111/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5574 - f1: 0.6542 - val_loss: 0.5857 - val_f1: 0.6250\n",
      "Epoch 112/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5601 - f1: 0.6550 - val_loss: 0.5860 - val_f1: 0.6254\n",
      "Epoch 113/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5578 - f1: 0.6514 - val_loss: 0.5853 - val_f1: 0.6301\n",
      "Epoch 114/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5561 - f1: 0.6599 - val_loss: 0.5869 - val_f1: 0.6193\n",
      "Epoch 115/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5535 - f1: 0.6566 - val_loss: 0.5873 - val_f1: 0.6302\n",
      "Epoch 116/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5574 - f1: 0.6537 - val_loss: 0.5878 - val_f1: 0.6218\n",
      "Epoch 117/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5572 - f1: 0.6490 - val_loss: 0.5870 - val_f1: 0.6315\n",
      "Epoch 118/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5545 - f1: 0.6611 - val_loss: 0.5869 - val_f1: 0.6268\n",
      "Epoch 119/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5589 - f1: 0.6504 - val_loss: 0.5882 - val_f1: 0.6297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5568 - f1: 0.6587 - val_loss: 0.5887 - val_f1: 0.6258\n",
      "Epoch 121/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5553 - f1: 0.6563 - val_loss: 0.5888 - val_f1: 0.6327\n",
      "Epoch 122/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5569 - f1: 0.6625 - val_loss: 0.5881 - val_f1: 0.6251\n",
      "Epoch 123/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5577 - f1: 0.6583 - val_loss: 0.5879 - val_f1: 0.6283\n",
      "Epoch 124/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5564 - f1: 0.6585 - val_loss: 0.5895 - val_f1: 0.6294\n",
      "Epoch 125/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5549 - f1: 0.6542 - val_loss: 0.5899 - val_f1: 0.6236\n",
      "Epoch 126/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5529 - f1: 0.6565 - val_loss: 0.5897 - val_f1: 0.6263\n",
      "Epoch 127/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5577 - f1: 0.6593 - val_loss: 0.5896 - val_f1: 0.6150\n",
      "Epoch 128/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5539 - f1: 0.6545 - val_loss: 0.5906 - val_f1: 0.6214\n",
      "Epoch 129/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5559 - f1: 0.6574 - val_loss: 0.5900 - val_f1: 0.6282\n",
      "Epoch 130/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5536 - f1: 0.6586 - val_loss: 0.5899 - val_f1: 0.6361\n",
      "Epoch 131/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5571 - f1: 0.6568 - val_loss: 0.5897 - val_f1: 0.6260\n",
      "Epoch 132/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5551 - f1: 0.6534 - val_loss: 0.5908 - val_f1: 0.6230\n",
      "Epoch 133/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5540 - f1: 0.6587 - val_loss: 0.5904 - val_f1: 0.6363\n",
      "Epoch 134/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5549 - f1: 0.6569 - val_loss: 0.5906 - val_f1: 0.6264\n",
      "Epoch 135/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5531 - f1: 0.6571 - val_loss: 0.5912 - val_f1: 0.6284\n",
      "Epoch 136/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5553 - f1: 0.6506 - val_loss: 0.5907 - val_f1: 0.6223\n",
      "Epoch 137/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5507 - f1: 0.6616 - val_loss: 0.5906 - val_f1: 0.6247\n",
      "Epoch 138/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5535 - f1: 0.6604 - val_loss: 0.5896 - val_f1: 0.6244\n",
      "Epoch 139/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5520 - f1: 0.6574 - val_loss: 0.5913 - val_f1: 0.6225\n",
      "Epoch 140/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5546 - f1: 0.6584 - val_loss: 0.5914 - val_f1: 0.6333\n",
      "Epoch 141/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5483 - f1: 0.6660 - val_loss: 0.5918 - val_f1: 0.6367\n",
      "Epoch 142/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5517 - f1: 0.6570 - val_loss: 0.5925 - val_f1: 0.6246\n",
      "Epoch 143/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5529 - f1: 0.6588 - val_loss: 0.5915 - val_f1: 0.6217\n",
      "Epoch 144/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5530 - f1: 0.6582 - val_loss: 0.5912 - val_f1: 0.6210\n",
      "Epoch 145/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5513 - f1: 0.6636 - val_loss: 0.5909 - val_f1: 0.6280\n",
      "Epoch 146/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5527 - f1: 0.6552 - val_loss: 0.5902 - val_f1: 0.6175\n",
      "Epoch 147/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5479 - f1: 0.6623 - val_loss: 0.5911 - val_f1: 0.6314\n",
      "Epoch 148/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5556 - f1: 0.6598 - val_loss: 0.5903 - val_f1: 0.6298\n",
      "Epoch 149/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5519 - f1: 0.6596 - val_loss: 0.5917 - val_f1: 0.6284\n",
      "Epoch 150/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5493 - f1: 0.6668 - val_loss: 0.5913 - val_f1: 0.6279\n",
      "Epoch 151/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5518 - f1: 0.6619 - val_loss: 0.5914 - val_f1: 0.6229\n",
      "Epoch 152/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5512 - f1: 0.6663 - val_loss: 0.5908 - val_f1: 0.6228\n",
      "Epoch 153/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5450 - f1: 0.6716 - val_loss: 0.5900 - val_f1: 0.6359\n",
      "Epoch 154/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5519 - f1: 0.6547 - val_loss: 0.5913 - val_f1: 0.6222\n",
      "Epoch 155/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5496 - f1: 0.6566 - val_loss: 0.5914 - val_f1: 0.6324\n",
      "Epoch 156/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5478 - f1: 0.6614 - val_loss: 0.5916 - val_f1: 0.6300\n",
      "Epoch 157/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5533 - f1: 0.6638 - val_loss: 0.5914 - val_f1: 0.6276\n",
      "Epoch 158/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5494 - f1: 0.6594 - val_loss: 0.5921 - val_f1: 0.6220\n",
      "Epoch 159/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5463 - f1: 0.6654 - val_loss: 0.5920 - val_f1: 0.6175\n",
      "Epoch 160/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5480 - f1: 0.6684 - val_loss: 0.5916 - val_f1: 0.6233\n",
      "Epoch 161/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5506 - f1: 0.6639 - val_loss: 0.5906 - val_f1: 0.6317\n",
      "Epoch 162/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5487 - f1: 0.6634 - val_loss: 0.5917 - val_f1: 0.6233\n",
      "Epoch 163/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5469 - f1: 0.6700 - val_loss: 0.5897 - val_f1: 0.6329\n",
      "Epoch 164/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5455 - f1: 0.6704 - val_loss: 0.5911 - val_f1: 0.6281\n",
      "Epoch 165/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5478 - f1: 0.6599 - val_loss: 0.5920 - val_f1: 0.6324\n",
      "Epoch 166/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5484 - f1: 0.6618 - val_loss: 0.5909 - val_f1: 0.6319\n",
      "Epoch 167/5000\n",
      "7667/7667 [==============================] - 1s 152us/step - loss: 0.5483 - f1: 0.6655 - val_loss: 0.5910 - val_f1: 0.6336\n",
      "Epoch 168/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5492 - f1: 0.6683 - val_loss: 0.5922 - val_f1: 0.6330\n",
      "Epoch 169/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5466 - f1: 0.6642 - val_loss: 0.5928 - val_f1: 0.6382\n",
      "Epoch 170/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5474 - f1: 0.6719 - val_loss: 0.5930 - val_f1: 0.6297\n",
      "Epoch 171/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5473 - f1: 0.6584 - val_loss: 0.5932 - val_f1: 0.6291\n",
      "Epoch 172/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5490 - f1: 0.6672 - val_loss: 0.5925 - val_f1: 0.6264\n",
      "Epoch 173/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5457 - f1: 0.6662 - val_loss: 0.5917 - val_f1: 0.6418\n",
      "Epoch 174/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5488 - f1: 0.6702 - val_loss: 0.5929 - val_f1: 0.6199\n",
      "Epoch 175/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5448 - f1: 0.6717 - val_loss: 0.5918 - val_f1: 0.6272\n",
      "Epoch 176/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5453 - f1: 0.6694 - val_loss: 0.5923 - val_f1: 0.6254\n",
      "Epoch 177/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5438 - f1: 0.6683 - val_loss: 0.5919 - val_f1: 0.6278\n",
      "Epoch 178/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5456 - f1: 0.6711 - val_loss: 0.5912 - val_f1: 0.6268\n",
      "Epoch 179/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5477 - f1: 0.6629 - val_loss: 0.5905 - val_f1: 0.6276\n",
      "Epoch 180/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5472 - f1: 0.6652 - val_loss: 0.5914 - val_f1: 0.6281\n",
      "Epoch 181/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5450 - f1: 0.6682 - val_loss: 0.5918 - val_f1: 0.6326\n",
      "Epoch 182/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5502 - f1: 0.6644 - val_loss: 0.5918 - val_f1: 0.6313\n",
      "Epoch 183/5000\n",
      "7667/7667 [==============================] - 1s 154us/step - loss: 0.5461 - f1: 0.6639 - val_loss: 0.5902 - val_f1: 0.6353\n",
      "Epoch 184/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5452 - f1: 0.6791 - val_loss: 0.5911 - val_f1: 0.6264\n",
      "Epoch 185/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5418 - f1: 0.6775 - val_loss: 0.5910 - val_f1: 0.6250\n",
      "Epoch 186/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5476 - f1: 0.6674 - val_loss: 0.5914 - val_f1: 0.6345\n",
      "Epoch 187/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5429 - f1: 0.6655 - val_loss: 0.5913 - val_f1: 0.6278\n",
      "Epoch 188/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5436 - f1: 0.6708 - val_loss: 0.5926 - val_f1: 0.6201\n",
      "Epoch 189/5000\n",
      "7667/7667 [==============================] - 1s 128us/step - loss: 0.5447 - f1: 0.6651 - val_loss: 0.5930 - val_f1: 0.6289\n",
      "Epoch 190/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5454 - f1: 0.6669 - val_loss: 0.5929 - val_f1: 0.6153\n",
      "Epoch 191/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5437 - f1: 0.6694 - val_loss: 0.5917 - val_f1: 0.6333\n",
      "Epoch 192/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5423 - f1: 0.6750 - val_loss: 0.5906 - val_f1: 0.6372\n",
      "Epoch 193/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5413 - f1: 0.6723 - val_loss: 0.5917 - val_f1: 0.6222\n",
      "Epoch 194/5000\n",
      "7667/7667 [==============================] - 1s 129us/step - loss: 0.5457 - f1: 0.6659 - val_loss: 0.5909 - val_f1: 0.6323\n",
      "Epoch 195/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5415 - f1: 0.6746 - val_loss: 0.5930 - val_f1: 0.6325\n",
      "Epoch 196/5000\n",
      "7667/7667 [==============================] - 1s 129us/step - loss: 0.5417 - f1: 0.6736 - val_loss: 0.5934 - val_f1: 0.6297\n",
      "Epoch 197/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5454 - f1: 0.6683 - val_loss: 0.5921 - val_f1: 0.6268\n",
      "Epoch 198/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5464 - f1: 0.6709 - val_loss: 0.5928 - val_f1: 0.6222\n",
      "Epoch 199/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5443 - f1: 0.6700 - val_loss: 0.5925 - val_f1: 0.6292\n",
      "Epoch 200/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5422 - f1: 0.6696 - val_loss: 0.5914 - val_f1: 0.6269\n",
      "Epoch 201/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5425 - f1: 0.6737 - val_loss: 0.5930 - val_f1: 0.6352\n",
      "Epoch 202/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5435 - f1: 0.6780 - val_loss: 0.5915 - val_f1: 0.6315\n",
      "Epoch 203/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5433 - f1: 0.6717 - val_loss: 0.5928 - val_f1: 0.6311\n",
      "Epoch 204/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5411 - f1: 0.6728 - val_loss: 0.5938 - val_f1: 0.6309\n",
      "Epoch 205/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5405 - f1: 0.6732 - val_loss: 0.5938 - val_f1: 0.6350\n",
      "Epoch 206/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5398 - f1: 0.6735 - val_loss: 0.5930 - val_f1: 0.6268\n",
      "Epoch 207/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5407 - f1: 0.6731 - val_loss: 0.5916 - val_f1: 0.6301\n",
      "Epoch 208/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5431 - f1: 0.6720 - val_loss: 0.5917 - val_f1: 0.6215\n",
      "Epoch 209/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5392 - f1: 0.6664 - val_loss: 0.5926 - val_f1: 0.6332\n",
      "Epoch 210/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5437 - f1: 0.6720 - val_loss: 0.5931 - val_f1: 0.6318\n",
      "Epoch 211/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5394 - f1: 0.6689 - val_loss: 0.5943 - val_f1: 0.6299\n",
      "Epoch 212/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5437 - f1: 0.6713 - val_loss: 0.5938 - val_f1: 0.6179\n",
      "Epoch 213/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5400 - f1: 0.6756 - val_loss: 0.5944 - val_f1: 0.6283\n",
      "Epoch 214/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5395 - f1: 0.6764 - val_loss: 0.5933 - val_f1: 0.6319\n",
      "Epoch 215/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5423 - f1: 0.6730 - val_loss: 0.5933 - val_f1: 0.6247\n",
      "Epoch 216/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5399 - f1: 0.6709 - val_loss: 0.5926 - val_f1: 0.6276\n",
      "Epoch 217/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5414 - f1: 0.6761 - val_loss: 0.5926 - val_f1: 0.6262\n",
      "Epoch 218/5000\n",
      "7667/7667 [==============================] - 1s 169us/step - loss: 0.5365 - f1: 0.6751 - val_loss: 0.5937 - val_f1: 0.6255\n",
      "Epoch 219/5000\n",
      "7667/7667 [==============================] - 1s 155us/step - loss: 0.5382 - f1: 0.6777 - val_loss: 0.5943 - val_f1: 0.6343\n",
      "Epoch 220/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5414 - f1: 0.6754 - val_loss: 0.5958 - val_f1: 0.6269\n",
      "Epoch 221/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5394 - f1: 0.6801 - val_loss: 0.5930 - val_f1: 0.6362\n",
      "Epoch 222/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5367 - f1: 0.6758 - val_loss: 0.5937 - val_f1: 0.6489\n",
      "Epoch 223/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5430 - f1: 0.6699 - val_loss: 0.5956 - val_f1: 0.6240\n",
      "Epoch 224/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5402 - f1: 0.6786 - val_loss: 0.5924 - val_f1: 0.6382\n",
      "Epoch 225/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5397 - f1: 0.6771 - val_loss: 0.5964 - val_f1: 0.6241\n",
      "Epoch 226/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5353 - f1: 0.6779 - val_loss: 0.5958 - val_f1: 0.6278\n",
      "Epoch 227/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5398 - f1: 0.6763 - val_loss: 0.5928 - val_f1: 0.6281\n",
      "Epoch 228/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5390 - f1: 0.6709 - val_loss: 0.5942 - val_f1: 0.6283\n",
      "Epoch 229/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5404 - f1: 0.6735 - val_loss: 0.5951 - val_f1: 0.6241\n",
      "Epoch 230/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5389 - f1: 0.6776 - val_loss: 0.5945 - val_f1: 0.6350\n",
      "Epoch 231/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5450 - f1: 0.6664 - val_loss: 0.5949 - val_f1: 0.6333\n",
      "Epoch 232/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5402 - f1: 0.6799 - val_loss: 0.5955 - val_f1: 0.6313\n",
      "Epoch 233/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5348 - f1: 0.6743 - val_loss: 0.5940 - val_f1: 0.6275\n",
      "Epoch 234/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5389 - f1: 0.6671 - val_loss: 0.5943 - val_f1: 0.6394\n",
      "Epoch 235/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5340 - f1: 0.6752 - val_loss: 0.5972 - val_f1: 0.6276\n",
      "Epoch 236/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5407 - f1: 0.6753 - val_loss: 0.5958 - val_f1: 0.6451\n",
      "Epoch 237/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5367 - f1: 0.6804 - val_loss: 0.5957 - val_f1: 0.6256\n",
      "Epoch 238/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5387 - f1: 0.6760 - val_loss: 0.5947 - val_f1: 0.6288\n",
      "Epoch 239/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5359 - f1: 0.6765 - val_loss: 0.5961 - val_f1: 0.6292\n",
      "Epoch 240/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5414 - f1: 0.6723 - val_loss: 0.5938 - val_f1: 0.6350\n",
      "Epoch 241/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5407 - f1: 0.6735 - val_loss: 0.5944 - val_f1: 0.6279\n",
      "Epoch 242/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5372 - f1: 0.6739 - val_loss: 0.5960 - val_f1: 0.6323\n",
      "Epoch 243/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5359 - f1: 0.6773 - val_loss: 0.5952 - val_f1: 0.6451\n",
      "Epoch 244/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5388 - f1: 0.6758 - val_loss: 0.5954 - val_f1: 0.6365\n",
      "Epoch 245/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5370 - f1: 0.6782 - val_loss: 0.5954 - val_f1: 0.6360\n",
      "Epoch 246/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5389 - f1: 0.6752 - val_loss: 0.5938 - val_f1: 0.6278\n",
      "Epoch 247/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5365 - f1: 0.6778 - val_loss: 0.5940 - val_f1: 0.6512\n",
      "Epoch 248/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5385 - f1: 0.6770 - val_loss: 0.5961 - val_f1: 0.6212\n",
      "Epoch 249/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5359 - f1: 0.6786 - val_loss: 0.5950 - val_f1: 0.6371\n",
      "Epoch 250/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5380 - f1: 0.6761 - val_loss: 0.5959 - val_f1: 0.6422\n",
      "Epoch 251/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5339 - f1: 0.6782 - val_loss: 0.5947 - val_f1: 0.6289\n",
      "Epoch 252/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5360 - f1: 0.6793 - val_loss: 0.5953 - val_f1: 0.6353\n",
      "Epoch 253/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5380 - f1: 0.6800 - val_loss: 0.5941 - val_f1: 0.6354\n",
      "Epoch 254/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5393 - f1: 0.6801 - val_loss: 0.5946 - val_f1: 0.6327\n",
      "Epoch 255/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5386 - f1: 0.6707 - val_loss: 0.5958 - val_f1: 0.6247\n",
      "Epoch 256/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5347 - f1: 0.6808 - val_loss: 0.5956 - val_f1: 0.6329\n",
      "Epoch 257/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5350 - f1: 0.6807 - val_loss: 0.5941 - val_f1: 0.6427\n",
      "Epoch 258/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5361 - f1: 0.6779 - val_loss: 0.5966 - val_f1: 0.6293\n",
      "Epoch 259/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5341 - f1: 0.6828 - val_loss: 0.5956 - val_f1: 0.6321\n",
      "Epoch 260/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5378 - f1: 0.6800 - val_loss: 0.5979 - val_f1: 0.6366\n",
      "Epoch 261/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5369 - f1: 0.6724 - val_loss: 0.5949 - val_f1: 0.6342\n",
      "Epoch 262/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5350 - f1: 0.6770 - val_loss: 0.5941 - val_f1: 0.6329\n",
      "Epoch 263/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5332 - f1: 0.6791 - val_loss: 0.5966 - val_f1: 0.6262\n",
      "Epoch 264/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5330 - f1: 0.6806 - val_loss: 0.5947 - val_f1: 0.6321\n",
      "Epoch 265/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5369 - f1: 0.6773 - val_loss: 0.5959 - val_f1: 0.6282\n",
      "Epoch 266/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5375 - f1: 0.6822 - val_loss: 0.5958 - val_f1: 0.6445\n",
      "Epoch 267/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5387 - f1: 0.6774 - val_loss: 0.5964 - val_f1: 0.6341\n",
      "Epoch 268/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5351 - f1: 0.6801 - val_loss: 0.5956 - val_f1: 0.6421\n",
      "Epoch 269/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5364 - f1: 0.6787 - val_loss: 0.5958 - val_f1: 0.6436\n",
      "Epoch 270/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5358 - f1: 0.6838 - val_loss: 0.5949 - val_f1: 0.6382\n",
      "Epoch 271/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5380 - f1: 0.6789 - val_loss: 0.5945 - val_f1: 0.6406\n",
      "Epoch 272/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5328 - f1: 0.6776 - val_loss: 0.5973 - val_f1: 0.6392\n",
      "Epoch 273/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5318 - f1: 0.6770 - val_loss: 0.5963 - val_f1: 0.6304\n",
      "Epoch 274/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5327 - f1: 0.6822 - val_loss: 0.5953 - val_f1: 0.6400\n",
      "Epoch 275/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5321 - f1: 0.6813 - val_loss: 0.5971 - val_f1: 0.6270\n",
      "Epoch 276/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5340 - f1: 0.6796 - val_loss: 0.5959 - val_f1: 0.6423\n",
      "Epoch 277/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5321 - f1: 0.6801 - val_loss: 0.5937 - val_f1: 0.6535\n",
      "Epoch 278/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5369 - f1: 0.6834 - val_loss: 0.5940 - val_f1: 0.6312\n",
      "Epoch 279/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5302 - f1: 0.6785 - val_loss: 0.5954 - val_f1: 0.6393\n",
      "Epoch 280/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5341 - f1: 0.6772 - val_loss: 0.5939 - val_f1: 0.6451\n",
      "Epoch 281/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5357 - f1: 0.6846 - val_loss: 0.5974 - val_f1: 0.6328\n",
      "Epoch 282/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5347 - f1: 0.6768 - val_loss: 0.5947 - val_f1: 0.6275\n",
      "Epoch 283/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5421 - f1: 0.6720 - val_loss: 0.5943 - val_f1: 0.6379\n",
      "Epoch 284/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5330 - f1: 0.6816 - val_loss: 0.5966 - val_f1: 0.6430\n",
      "Epoch 285/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5316 - f1: 0.6797 - val_loss: 0.5951 - val_f1: 0.6415\n",
      "Epoch 286/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5350 - f1: 0.6863 - val_loss: 0.5966 - val_f1: 0.6316\n",
      "Epoch 287/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5389 - f1: 0.6780 - val_loss: 0.5942 - val_f1: 0.6445\n",
      "Epoch 288/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5358 - f1: 0.6781 - val_loss: 0.5947 - val_f1: 0.6412\n",
      "Epoch 289/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5330 - f1: 0.6830 - val_loss: 0.5953 - val_f1: 0.6259\n",
      "Epoch 290/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5366 - f1: 0.6752 - val_loss: 0.5947 - val_f1: 0.6393\n",
      "Epoch 291/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5372 - f1: 0.6763 - val_loss: 0.5965 - val_f1: 0.6339\n",
      "Epoch 292/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5329 - f1: 0.6801 - val_loss: 0.5938 - val_f1: 0.6444\n",
      "Epoch 293/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5343 - f1: 0.6862 - val_loss: 0.5926 - val_f1: 0.6486\n",
      "Epoch 294/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5366 - f1: 0.6742 - val_loss: 0.5948 - val_f1: 0.6489\n",
      "Epoch 295/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5348 - f1: 0.6803 - val_loss: 0.5943 - val_f1: 0.6313\n",
      "Epoch 296/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5347 - f1: 0.6773 - val_loss: 0.5964 - val_f1: 0.6205\n",
      "Epoch 297/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5336 - f1: 0.6765 - val_loss: 0.5963 - val_f1: 0.6286\n",
      "Epoch 298/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5330 - f1: 0.6791 - val_loss: 0.5966 - val_f1: 0.6315\n",
      "Epoch 299/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5344 - f1: 0.6747 - val_loss: 0.5966 - val_f1: 0.6273\n",
      "Epoch 300/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5329 - f1: 0.6742 - val_loss: 0.5964 - val_f1: 0.6234\n",
      "Epoch 301/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5276 - f1: 0.6767 - val_loss: 0.5961 - val_f1: 0.6346\n",
      "Epoch 302/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5341 - f1: 0.6781 - val_loss: 0.5958 - val_f1: 0.6329\n",
      "Epoch 303/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5349 - f1: 0.6763 - val_loss: 0.5963 - val_f1: 0.6340\n",
      "Epoch 304/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5315 - f1: 0.6848 - val_loss: 0.5949 - val_f1: 0.6280\n",
      "Epoch 305/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5318 - f1: 0.6849 - val_loss: 0.5945 - val_f1: 0.6427\n",
      "Epoch 306/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5349 - f1: 0.6797 - val_loss: 0.5950 - val_f1: 0.6336\n",
      "Epoch 307/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5336 - f1: 0.6874 - val_loss: 0.5956 - val_f1: 0.6338\n",
      "Epoch 308/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5312 - f1: 0.6826 - val_loss: 0.5949 - val_f1: 0.6325\n",
      "Epoch 309/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5346 - f1: 0.6834 - val_loss: 0.5925 - val_f1: 0.6346\n",
      "Epoch 310/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5337 - f1: 0.6847 - val_loss: 0.5931 - val_f1: 0.6340\n",
      "Epoch 311/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5329 - f1: 0.6841 - val_loss: 0.5960 - val_f1: 0.6182\n",
      "Epoch 312/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5308 - f1: 0.6820 - val_loss: 0.5960 - val_f1: 0.6260\n",
      "Epoch 313/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5336 - f1: 0.6815 - val_loss: 0.5936 - val_f1: 0.6331\n",
      "Epoch 314/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5297 - f1: 0.6906 - val_loss: 0.5952 - val_f1: 0.6207\n",
      "Epoch 315/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5308 - f1: 0.6820 - val_loss: 0.5953 - val_f1: 0.6379\n",
      "Epoch 316/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5318 - f1: 0.6792 - val_loss: 0.5975 - val_f1: 0.6266\n",
      "Epoch 317/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5324 - f1: 0.6819 - val_loss: 0.5959 - val_f1: 0.6393\n",
      "Epoch 318/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5306 - f1: 0.6859 - val_loss: 0.5930 - val_f1: 0.6409\n",
      "Epoch 319/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5363 - f1: 0.6799 - val_loss: 0.5934 - val_f1: 0.6272\n",
      "Epoch 320/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5288 - f1: 0.6887 - val_loss: 0.5970 - val_f1: 0.6228\n",
      "Epoch 321/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5326 - f1: 0.6818 - val_loss: 0.5951 - val_f1: 0.6340\n",
      "Epoch 322/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5315 - f1: 0.6816 - val_loss: 0.5944 - val_f1: 0.6416\n",
      "Epoch 323/5000\n",
      "7667/7667 [==============================] - 1s 155us/step - loss: 0.5322 - f1: 0.6862 - val_loss: 0.5952 - val_f1: 0.6351\n",
      "Epoch 324/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5331 - f1: 0.6824 - val_loss: 0.5964 - val_f1: 0.6345\n",
      "Epoch 325/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5290 - f1: 0.6841 - val_loss: 0.5964 - val_f1: 0.6286\n",
      "Epoch 326/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5349 - f1: 0.6817 - val_loss: 0.5974 - val_f1: 0.6309\n",
      "Epoch 327/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5251 - f1: 0.6938 - val_loss: 0.5984 - val_f1: 0.6347\n",
      "Epoch 328/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5273 - f1: 0.6856 - val_loss: 0.5985 - val_f1: 0.6249\n",
      "Epoch 329/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5313 - f1: 0.6799 - val_loss: 0.5972 - val_f1: 0.6360\n",
      "Epoch 330/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5283 - f1: 0.6897 - val_loss: 0.5968 - val_f1: 0.6391\n",
      "Epoch 331/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5299 - f1: 0.6780 - val_loss: 0.5969 - val_f1: 0.6311\n",
      "Epoch 332/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5303 - f1: 0.6819 - val_loss: 0.6000 - val_f1: 0.6310\n",
      "Epoch 333/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5288 - f1: 0.6813 - val_loss: 0.5983 - val_f1: 0.6283\n",
      "Epoch 334/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5280 - f1: 0.6912 - val_loss: 0.5988 - val_f1: 0.6287\n",
      "Epoch 335/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5311 - f1: 0.6786 - val_loss: 0.5986 - val_f1: 0.6345\n",
      "Epoch 336/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5244 - f1: 0.6913 - val_loss: 0.5975 - val_f1: 0.6359\n",
      "Epoch 337/5000\n",
      "7667/7667 [==============================] - 1s 154us/step - loss: 0.5296 - f1: 0.6878 - val_loss: 0.5981 - val_f1: 0.6425\n",
      "Epoch 338/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5295 - f1: 0.6824 - val_loss: 0.5982 - val_f1: 0.6317\n",
      "Epoch 339/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5350 - f1: 0.6767 - val_loss: 0.5966 - val_f1: 0.6369\n",
      "Epoch 340/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5368 - f1: 0.6834 - val_loss: 0.5974 - val_f1: 0.6289\n",
      "Epoch 341/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5324 - f1: 0.6786 - val_loss: 0.5980 - val_f1: 0.6388\n",
      "Epoch 342/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5268 - f1: 0.6827 - val_loss: 0.5987 - val_f1: 0.6333\n",
      "Epoch 343/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5305 - f1: 0.6859 - val_loss: 0.5972 - val_f1: 0.6296\n",
      "Epoch 344/5000\n",
      "7667/7667 [==============================] - 1s 161us/step - loss: 0.5252 - f1: 0.6865 - val_loss: 0.5972 - val_f1: 0.6360\n",
      "Epoch 345/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5320 - f1: 0.6776 - val_loss: 0.5975 - val_f1: 0.6397\n",
      "Epoch 346/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5342 - f1: 0.6787 - val_loss: 0.5979 - val_f1: 0.6378\n",
      "Epoch 347/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5279 - f1: 0.6841 - val_loss: 0.5975 - val_f1: 0.6333\n",
      "Epoch 348/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5291 - f1: 0.6837 - val_loss: 0.5993 - val_f1: 0.6251\n",
      "Epoch 349/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5291 - f1: 0.6870 - val_loss: 0.5981 - val_f1: 0.6317\n",
      "Epoch 350/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5287 - f1: 0.6829 - val_loss: 0.5974 - val_f1: 0.6490\n",
      "Epoch 351/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5259 - f1: 0.6801 - val_loss: 0.5988 - val_f1: 0.6433\n",
      "Epoch 352/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5319 - f1: 0.6772 - val_loss: 0.5960 - val_f1: 0.6297\n",
      "Epoch 353/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5262 - f1: 0.6876 - val_loss: 0.5969 - val_f1: 0.6447\n",
      "Epoch 354/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5310 - f1: 0.6832 - val_loss: 0.5960 - val_f1: 0.6363\n",
      "Epoch 355/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5274 - f1: 0.6837 - val_loss: 0.5968 - val_f1: 0.6314\n",
      "Epoch 356/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5286 - f1: 0.6884 - val_loss: 0.5973 - val_f1: 0.6365\n",
      "Epoch 357/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5244 - f1: 0.6877 - val_loss: 0.5968 - val_f1: 0.6376\n",
      "Epoch 358/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5270 - f1: 0.6863 - val_loss: 0.6003 - val_f1: 0.6303\n",
      "Epoch 359/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5300 - f1: 0.6837 - val_loss: 0.5990 - val_f1: 0.6418\n",
      "Epoch 360/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5309 - f1: 0.6813 - val_loss: 0.5999 - val_f1: 0.6439\n",
      "Epoch 361/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5261 - f1: 0.6898 - val_loss: 0.5994 - val_f1: 0.6246\n",
      "Epoch 362/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5307 - f1: 0.6899 - val_loss: 0.5995 - val_f1: 0.6309\n",
      "Epoch 363/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5284 - f1: 0.6823 - val_loss: 0.5976 - val_f1: 0.6292\n",
      "Epoch 364/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5249 - f1: 0.6939 - val_loss: 0.5998 - val_f1: 0.6391\n",
      "Epoch 365/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5274 - f1: 0.6872 - val_loss: 0.5992 - val_f1: 0.6397\n",
      "Epoch 366/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5315 - f1: 0.6827 - val_loss: 0.5979 - val_f1: 0.6391\n",
      "Epoch 367/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5294 - f1: 0.6849 - val_loss: 0.5988 - val_f1: 0.6428\n",
      "Epoch 368/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5307 - f1: 0.6870 - val_loss: 0.5989 - val_f1: 0.6363\n",
      "Epoch 369/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5253 - f1: 0.6861 - val_loss: 0.5996 - val_f1: 0.6393\n",
      "Epoch 370/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5272 - f1: 0.6851 - val_loss: 0.5977 - val_f1: 0.6419\n",
      "Epoch 371/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5306 - f1: 0.6850 - val_loss: 0.5964 - val_f1: 0.6351\n",
      "Epoch 372/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5252 - f1: 0.6888 - val_loss: 0.5963 - val_f1: 0.6310\n",
      "Epoch 373/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5275 - f1: 0.6841 - val_loss: 0.5981 - val_f1: 0.6283\n",
      "Epoch 374/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5289 - f1: 0.6865 - val_loss: 0.6008 - val_f1: 0.6339\n",
      "Epoch 375/5000\n",
      "7667/7667 [==============================] - 1s 129us/step - loss: 0.5301 - f1: 0.6891 - val_loss: 0.5999 - val_f1: 0.6353\n",
      "Epoch 376/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5278 - f1: 0.6896 - val_loss: 0.6024 - val_f1: 0.6191\n",
      "Epoch 377/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5283 - f1: 0.6827 - val_loss: 0.5990 - val_f1: 0.6447\n",
      "Epoch 378/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5300 - f1: 0.6864 - val_loss: 0.6004 - val_f1: 0.6442\n",
      "Epoch 379/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5287 - f1: 0.6861 - val_loss: 0.5986 - val_f1: 0.6338\n",
      "Epoch 380/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5298 - f1: 0.6883 - val_loss: 0.5993 - val_f1: 0.6389\n",
      "Epoch 381/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5276 - f1: 0.6891 - val_loss: 0.6009 - val_f1: 0.6346\n",
      "Epoch 382/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5259 - f1: 0.6862 - val_loss: 0.6011 - val_f1: 0.6442\n",
      "Epoch 383/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5243 - f1: 0.6941 - val_loss: 0.6002 - val_f1: 0.6462\n",
      "Epoch 384/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5228 - f1: 0.6937 - val_loss: 0.6002 - val_f1: 0.6447\n",
      "Epoch 385/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5219 - f1: 0.6893 - val_loss: 0.6008 - val_f1: 0.6442\n",
      "Epoch 386/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5338 - f1: 0.6846 - val_loss: 0.5981 - val_f1: 0.6337\n",
      "Epoch 387/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5244 - f1: 0.6847 - val_loss: 0.6004 - val_f1: 0.6411\n",
      "Epoch 388/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5293 - f1: 0.6860 - val_loss: 0.5998 - val_f1: 0.6296\n",
      "Epoch 389/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5305 - f1: 0.6834 - val_loss: 0.6014 - val_f1: 0.6294\n",
      "Epoch 390/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5266 - f1: 0.6937 - val_loss: 0.6011 - val_f1: 0.6348\n",
      "Epoch 391/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5260 - f1: 0.6899 - val_loss: 0.6020 - val_f1: 0.6396\n",
      "Epoch 392/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5284 - f1: 0.6859 - val_loss: 0.6012 - val_f1: 0.6227\n",
      "Epoch 393/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5272 - f1: 0.6891 - val_loss: 0.6043 - val_f1: 0.6296\n",
      "Epoch 394/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5228 - f1: 0.6890 - val_loss: 0.6032 - val_f1: 0.6205\n",
      "Epoch 395/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5260 - f1: 0.6922 - val_loss: 0.6034 - val_f1: 0.6356\n",
      "Epoch 396/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5198 - f1: 0.6901 - val_loss: 0.6019 - val_f1: 0.6437\n",
      "Epoch 397/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5284 - f1: 0.6844 - val_loss: 0.6001 - val_f1: 0.6306\n",
      "Epoch 398/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5216 - f1: 0.6910 - val_loss: 0.6023 - val_f1: 0.6239\n",
      "Epoch 399/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5249 - f1: 0.6892 - val_loss: 0.6020 - val_f1: 0.6390\n",
      "Epoch 400/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5289 - f1: 0.6852 - val_loss: 0.6010 - val_f1: 0.6320\n",
      "Epoch 401/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5285 - f1: 0.6837 - val_loss: 0.5996 - val_f1: 0.6330\n",
      "Epoch 402/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5240 - f1: 0.6866 - val_loss: 0.6026 - val_f1: 0.6255\n",
      "Epoch 403/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5253 - f1: 0.6907 - val_loss: 0.6013 - val_f1: 0.6364\n",
      "Epoch 404/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5275 - f1: 0.6862 - val_loss: 0.6021 - val_f1: 0.6313\n",
      "Epoch 405/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5263 - f1: 0.6882 - val_loss: 0.6028 - val_f1: 0.6303\n",
      "Epoch 406/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5241 - f1: 0.6911 - val_loss: 0.6016 - val_f1: 0.6286\n",
      "Epoch 407/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5299 - f1: 0.6868 - val_loss: 0.5998 - val_f1: 0.6376\n",
      "Epoch 408/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5217 - f1: 0.6903 - val_loss: 0.6016 - val_f1: 0.6440\n",
      "Epoch 409/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5287 - f1: 0.6884 - val_loss: 0.6001 - val_f1: 0.6459\n",
      "Epoch 410/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5340 - f1: 0.6785 - val_loss: 0.6004 - val_f1: 0.6403\n",
      "Epoch 411/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5285 - f1: 0.6885 - val_loss: 0.6000 - val_f1: 0.6360\n",
      "Epoch 412/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5289 - f1: 0.6894 - val_loss: 0.6006 - val_f1: 0.6456\n",
      "Epoch 413/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5190 - f1: 0.6877 - val_loss: 0.5999 - val_f1: 0.6415\n",
      "Epoch 414/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5283 - f1: 0.6848 - val_loss: 0.6001 - val_f1: 0.6446\n",
      "Epoch 415/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5257 - f1: 0.6896 - val_loss: 0.6000 - val_f1: 0.6331\n",
      "Epoch 416/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5221 - f1: 0.6932 - val_loss: 0.6010 - val_f1: 0.6334\n",
      "Epoch 417/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5251 - f1: 0.6895 - val_loss: 0.5997 - val_f1: 0.6409\n",
      "Epoch 418/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5246 - f1: 0.6839 - val_loss: 0.5967 - val_f1: 0.6421\n",
      "Epoch 419/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5230 - f1: 0.6910 - val_loss: 0.6012 - val_f1: 0.6370\n",
      "Epoch 420/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5310 - f1: 0.6874 - val_loss: 0.6010 - val_f1: 0.6420\n",
      "Epoch 421/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5257 - f1: 0.6872 - val_loss: 0.6007 - val_f1: 0.6273\n",
      "Epoch 422/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5250 - f1: 0.6895 - val_loss: 0.6032 - val_f1: 0.6399\n",
      "Epoch 423/5000\n",
      "7667/7667 [==============================] - 1s 128us/step - loss: 0.5264 - f1: 0.6884 - val_loss: 0.6006 - val_f1: 0.6388\n",
      "Epoch 424/5000\n",
      "7667/7667 [==============================] - 1s 129us/step - loss: 0.5230 - f1: 0.6870 - val_loss: 0.6013 - val_f1: 0.6366\n",
      "Epoch 425/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5228 - f1: 0.6896 - val_loss: 0.6005 - val_f1: 0.6481\n",
      "Epoch 426/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5243 - f1: 0.6932 - val_loss: 0.6008 - val_f1: 0.6416\n",
      "Epoch 427/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5278 - f1: 0.6985 - val_loss: 0.6014 - val_f1: 0.6427\n",
      "Epoch 428/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5245 - f1: 0.6984 - val_loss: 0.6010 - val_f1: 0.6361\n",
      "Epoch 429/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5265 - f1: 0.6836 - val_loss: 0.6030 - val_f1: 0.6343\n",
      "Epoch 430/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5262 - f1: 0.6876 - val_loss: 0.6021 - val_f1: 0.6387\n",
      "Epoch 431/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5254 - f1: 0.6896 - val_loss: 0.6023 - val_f1: 0.6265\n",
      "Epoch 432/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5275 - f1: 0.6818 - val_loss: 0.6001 - val_f1: 0.6385\n",
      "Epoch 433/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5245 - f1: 0.6867 - val_loss: 0.6004 - val_f1: 0.6377\n",
      "Epoch 434/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5250 - f1: 0.6847 - val_loss: 0.6006 - val_f1: 0.6341\n",
      "Epoch 435/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5270 - f1: 0.6861 - val_loss: 0.6008 - val_f1: 0.6404\n",
      "Epoch 436/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5289 - f1: 0.6837 - val_loss: 0.6026 - val_f1: 0.6317\n",
      "Epoch 437/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5198 - f1: 0.6837 - val_loss: 0.6035 - val_f1: 0.6436\n",
      "Epoch 438/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5259 - f1: 0.6857 - val_loss: 0.6043 - val_f1: 0.6303\n",
      "Epoch 439/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5307 - f1: 0.6821 - val_loss: 0.6020 - val_f1: 0.6385\n",
      "Epoch 440/5000\n",
      "7667/7667 [==============================] - 1s 128us/step - loss: 0.5209 - f1: 0.6878 - val_loss: 0.6020 - val_f1: 0.6470\n",
      "Epoch 441/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5250 - f1: 0.6929 - val_loss: 0.6025 - val_f1: 0.6328\n",
      "Epoch 442/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5284 - f1: 0.6811 - val_loss: 0.6012 - val_f1: 0.6448\n",
      "Epoch 443/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5231 - f1: 0.6919 - val_loss: 0.6036 - val_f1: 0.6347\n",
      "Epoch 444/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5292 - f1: 0.6912 - val_loss: 0.6036 - val_f1: 0.6341\n",
      "Epoch 445/5000\n",
      "7667/7667 [==============================] - 1s 131us/step - loss: 0.5256 - f1: 0.6878 - val_loss: 0.6025 - val_f1: 0.6316\n",
      "Epoch 446/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5250 - f1: 0.6861 - val_loss: 0.6026 - val_f1: 0.6346\n",
      "Epoch 447/5000\n",
      "7667/7667 [==============================] - 1s 134us/step - loss: 0.5301 - f1: 0.6853 - val_loss: 0.6022 - val_f1: 0.6362\n",
      "Epoch 448/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5221 - f1: 0.6924 - val_loss: 0.6031 - val_f1: 0.6355\n",
      "Epoch 449/5000\n",
      "7667/7667 [==============================] - 1s 132us/step - loss: 0.5244 - f1: 0.6903 - val_loss: 0.6021 - val_f1: 0.6362\n",
      "Epoch 450/5000\n",
      "7667/7667 [==============================] - 1s 130us/step - loss: 0.5219 - f1: 0.6911 - val_loss: 0.6019 - val_f1: 0.6483\n",
      "Epoch 451/5000\n",
      "7667/7667 [==============================] - 1s 133us/step - loss: 0.5227 - f1: 0.6847 - val_loss: 0.6042 - val_f1: 0.6389\n",
      "Epoch 452/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5252 - f1: 0.6861 - val_loss: 0.6020 - val_f1: 0.6358\n",
      "Epoch 453/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5268 - f1: 0.6895 - val_loss: 0.6012 - val_f1: 0.6418\n",
      "Epoch 454/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5273 - f1: 0.6895 - val_loss: 0.6023 - val_f1: 0.6364\n",
      "Epoch 455/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5266 - f1: 0.6824 - val_loss: 0.6037 - val_f1: 0.6424\n",
      "Epoch 456/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5268 - f1: 0.6874 - val_loss: 0.6037 - val_f1: 0.6364\n",
      "Epoch 457/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5223 - f1: 0.6906 - val_loss: 0.6030 - val_f1: 0.6331\n",
      "Epoch 458/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5249 - f1: 0.6914 - val_loss: 0.6018 - val_f1: 0.6420\n",
      "Epoch 459/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5272 - f1: 0.6875 - val_loss: 0.6032 - val_f1: 0.6400\n",
      "Epoch 460/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5222 - f1: 0.6925 - val_loss: 0.6020 - val_f1: 0.6361\n",
      "Epoch 461/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5275 - f1: 0.6866 - val_loss: 0.6026 - val_f1: 0.6407\n",
      "Epoch 462/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5254 - f1: 0.6860 - val_loss: 0.6030 - val_f1: 0.6412\n",
      "Epoch 463/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5298 - f1: 0.6861 - val_loss: 0.6041 - val_f1: 0.6389\n",
      "Epoch 464/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5245 - f1: 0.6896 - val_loss: 0.6037 - val_f1: 0.6338\n",
      "Epoch 465/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5234 - f1: 0.6861 - val_loss: 0.6032 - val_f1: 0.6437\n",
      "Epoch 466/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5214 - f1: 0.6853 - val_loss: 0.6010 - val_f1: 0.6454\n",
      "Epoch 467/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5232 - f1: 0.6912 - val_loss: 0.6034 - val_f1: 0.6414\n",
      "Epoch 468/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5227 - f1: 0.6991 - val_loss: 0.6035 - val_f1: 0.6436\n",
      "Epoch 469/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5235 - f1: 0.6891 - val_loss: 0.6054 - val_f1: 0.6423\n",
      "Epoch 470/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5236 - f1: 0.6911 - val_loss: 0.6042 - val_f1: 0.6391\n",
      "Epoch 471/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5236 - f1: 0.6910 - val_loss: 0.6037 - val_f1: 0.6518\n",
      "Epoch 472/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5275 - f1: 0.6900 - val_loss: 0.6026 - val_f1: 0.6493\n",
      "Epoch 473/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5264 - f1: 0.6909 - val_loss: 0.6024 - val_f1: 0.6463\n",
      "Epoch 474/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5223 - f1: 0.6939 - val_loss: 0.6003 - val_f1: 0.6417\n",
      "Epoch 475/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5217 - f1: 0.6952 - val_loss: 0.6018 - val_f1: 0.6428\n",
      "Epoch 476/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5229 - f1: 0.6834 - val_loss: 0.6018 - val_f1: 0.6414\n",
      "Epoch 477/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5238 - f1: 0.6922 - val_loss: 0.6019 - val_f1: 0.6500\n",
      "Epoch 478/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5278 - f1: 0.6873 - val_loss: 0.6014 - val_f1: 0.6410\n",
      "Epoch 479/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5250 - f1: 0.6892 - val_loss: 0.6018 - val_f1: 0.6466\n",
      "Epoch 480/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5214 - f1: 0.6910 - val_loss: 0.6032 - val_f1: 0.6404\n",
      "Epoch 481/5000\n",
      "7667/7667 [==============================] - 1s 179us/step - loss: 0.5219 - f1: 0.6934 - val_loss: 0.6036 - val_f1: 0.6453\n",
      "Epoch 482/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5225 - f1: 0.6900 - val_loss: 0.6025 - val_f1: 0.6446\n",
      "Epoch 483/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5214 - f1: 0.6862 - val_loss: 0.6010 - val_f1: 0.6487\n",
      "Epoch 484/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5228 - f1: 0.6936 - val_loss: 0.6014 - val_f1: 0.6465\n",
      "Epoch 485/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5195 - f1: 0.6925 - val_loss: 0.6015 - val_f1: 0.6430\n",
      "Epoch 486/5000\n",
      "7667/7667 [==============================] - 1s 169us/step - loss: 0.5207 - f1: 0.6891 - val_loss: 0.6007 - val_f1: 0.6499\n",
      "Epoch 487/5000\n",
      "7667/7667 [==============================] - 1s 170us/step - loss: 0.5191 - f1: 0.6972 - val_loss: 0.6012 - val_f1: 0.6333\n",
      "Epoch 488/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5225 - f1: 0.6979 - val_loss: 0.6024 - val_f1: 0.6310\n",
      "Epoch 489/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5225 - f1: 0.6915 - val_loss: 0.6028 - val_f1: 0.6399\n",
      "Epoch 490/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5278 - f1: 0.6832 - val_loss: 0.6015 - val_f1: 0.6249\n",
      "Epoch 491/5000\n",
      "7667/7667 [==============================] - 1s 160us/step - loss: 0.5245 - f1: 0.6911 - val_loss: 0.6036 - val_f1: 0.6468\n",
      "Epoch 492/5000\n",
      "7667/7667 [==============================] - ETA: 0s - loss: 0.5261 - f1: 0.69 - 1s 154us/step - loss: 0.5248 - f1: 0.6922 - val_loss: 0.6044 - val_f1: 0.6462\n",
      "Epoch 493/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5219 - f1: 0.6929 - val_loss: 0.6026 - val_f1: 0.6466\n",
      "Epoch 494/5000\n",
      "7667/7667 [==============================] - 1s 159us/step - loss: 0.5219 - f1: 0.6979 - val_loss: 0.6029 - val_f1: 0.6452\n",
      "Epoch 495/5000\n",
      "7667/7667 [==============================] - 1s 173us/step - loss: 0.5275 - f1: 0.6880 - val_loss: 0.6020 - val_f1: 0.6523\n",
      "Epoch 496/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5245 - f1: 0.6925 - val_loss: 0.6042 - val_f1: 0.6486\n",
      "Epoch 497/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5175 - f1: 0.6930 - val_loss: 0.6032 - val_f1: 0.6355\n",
      "Epoch 498/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5209 - f1: 0.6915 - val_loss: 0.6028 - val_f1: 0.6365\n",
      "Epoch 499/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5220 - f1: 0.6973 - val_loss: 0.6022 - val_f1: 0.6485\n",
      "Epoch 500/5000\n",
      "7667/7667 [==============================] - 1s 156us/step - loss: 0.5163 - f1: 0.6959 - val_loss: 0.6022 - val_f1: 0.6425\n",
      "Epoch 501/5000\n",
      "7667/7667 [==============================] - 1s 167us/step - loss: 0.5205 - f1: 0.6947 - val_loss: 0.6031 - val_f1: 0.6472\n",
      "Epoch 502/5000\n",
      "7667/7667 [==============================] - 1s 172us/step - loss: 0.5217 - f1: 0.6871 - val_loss: 0.6008 - val_f1: 0.6412\n",
      "Epoch 503/5000\n",
      "7667/7667 [==============================] - 1s 172us/step - loss: 0.5193 - f1: 0.6879 - val_loss: 0.6013 - val_f1: 0.6492\n",
      "Epoch 504/5000\n",
      "7667/7667 [==============================] - 1s 169us/step - loss: 0.5202 - f1: 0.6918 - val_loss: 0.6019 - val_f1: 0.6443\n",
      "Epoch 505/5000\n",
      "7667/7667 [==============================] - 1s 169us/step - loss: 0.5246 - f1: 0.6872 - val_loss: 0.6016 - val_f1: 0.6379\n",
      "Epoch 506/5000\n",
      "7667/7667 [==============================] - 1s 167us/step - loss: 0.5264 - f1: 0.6920 - val_loss: 0.6018 - val_f1: 0.6389\n",
      "Epoch 507/5000\n",
      "7667/7667 [==============================] - 1s 158us/step - loss: 0.5175 - f1: 0.6936 - val_loss: 0.6023 - val_f1: 0.6354\n",
      "Epoch 508/5000\n",
      "7667/7667 [==============================] - 1s 188us/step - loss: 0.5205 - f1: 0.6932 - val_loss: 0.6046 - val_f1: 0.6369\n",
      "Epoch 509/5000\n",
      "7667/7667 [==============================] - 2s 213us/step - loss: 0.5249 - f1: 0.6906 - val_loss: 0.6028 - val_f1: 0.6470\n",
      "Epoch 510/5000\n",
      "7667/7667 [==============================] - 2s 199us/step - loss: 0.5211 - f1: 0.6938 - val_loss: 0.6018 - val_f1: 0.6375\n",
      "Epoch 511/5000\n",
      "7667/7667 [==============================] - 1s 161us/step - loss: 0.5224 - f1: 0.6928 - val_loss: 0.6020 - val_f1: 0.6460\n",
      "Epoch 512/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5220 - f1: 0.6965 - val_loss: 0.6037 - val_f1: 0.6268\n",
      "Epoch 513/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5208 - f1: 0.6905 - val_loss: 0.5997 - val_f1: 0.6402\n",
      "Epoch 514/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5211 - f1: 0.6942 - val_loss: 0.6023 - val_f1: 0.6419\n",
      "Epoch 515/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5255 - f1: 0.6831 - val_loss: 0.6024 - val_f1: 0.6458\n",
      "Epoch 516/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5222 - f1: 0.6934 - val_loss: 0.6014 - val_f1: 0.6350\n",
      "Epoch 517/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5242 - f1: 0.6795 - val_loss: 0.6017 - val_f1: 0.6354\n",
      "Epoch 518/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5228 - f1: 0.6911 - val_loss: 0.6019 - val_f1: 0.6195\n",
      "Epoch 519/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5205 - f1: 0.6936 - val_loss: 0.6031 - val_f1: 0.6404\n",
      "Epoch 520/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5184 - f1: 0.6965 - val_loss: 0.6026 - val_f1: 0.6558\n",
      "Epoch 521/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5235 - f1: 0.6920 - val_loss: 0.5998 - val_f1: 0.6403\n",
      "Epoch 522/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5204 - f1: 0.6955 - val_loss: 0.6018 - val_f1: 0.6372\n",
      "Epoch 523/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5246 - f1: 0.6856 - val_loss: 0.6008 - val_f1: 0.6311\n",
      "Epoch 524/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5216 - f1: 0.6905 - val_loss: 0.6003 - val_f1: 0.6444\n",
      "Epoch 525/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5199 - f1: 0.6926 - val_loss: 0.6000 - val_f1: 0.6251\n",
      "Epoch 526/5000\n",
      "7667/7667 [==============================] - 1s 152us/step - loss: 0.5201 - f1: 0.6915 - val_loss: 0.6035 - val_f1: 0.6444\n",
      "Epoch 527/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5234 - f1: 0.6965 - val_loss: 0.6032 - val_f1: 0.6562\n",
      "Epoch 528/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5207 - f1: 0.6987 - val_loss: 0.6016 - val_f1: 0.6519\n",
      "Epoch 529/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5234 - f1: 0.6900 - val_loss: 0.6012 - val_f1: 0.6448\n",
      "Epoch 530/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5211 - f1: 0.6939 - val_loss: 0.6037 - val_f1: 0.6462\n",
      "Epoch 531/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5187 - f1: 0.6904 - val_loss: 0.6000 - val_f1: 0.6432\n",
      "Epoch 532/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5216 - f1: 0.6897 - val_loss: 0.5993 - val_f1: 0.6327\n",
      "Epoch 533/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5180 - f1: 0.6890 - val_loss: 0.6019 - val_f1: 0.6448\n",
      "Epoch 534/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5238 - f1: 0.6913 - val_loss: 0.6008 - val_f1: 0.6463\n",
      "Epoch 535/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5196 - f1: 0.6956 - val_loss: 0.6024 - val_f1: 0.6458\n",
      "Epoch 536/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5201 - f1: 0.6981 - val_loss: 0.5999 - val_f1: 0.6410\n",
      "Epoch 537/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5221 - f1: 0.6953 - val_loss: 0.5982 - val_f1: 0.6463\n",
      "Epoch 538/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5222 - f1: 0.6878 - val_loss: 0.6005 - val_f1: 0.6301\n",
      "Epoch 539/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5185 - f1: 0.6975 - val_loss: 0.6038 - val_f1: 0.6434\n",
      "Epoch 540/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5210 - f1: 0.6922 - val_loss: 0.6022 - val_f1: 0.6309\n",
      "Epoch 541/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5229 - f1: 0.6899 - val_loss: 0.6039 - val_f1: 0.6464\n",
      "Epoch 542/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5221 - f1: 0.6930 - val_loss: 0.6019 - val_f1: 0.6443\n",
      "Epoch 543/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5176 - f1: 0.6880 - val_loss: 0.6022 - val_f1: 0.6460\n",
      "Epoch 544/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5197 - f1: 0.6922 - val_loss: 0.6024 - val_f1: 0.6424\n",
      "Epoch 545/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5205 - f1: 0.6961 - val_loss: 0.6001 - val_f1: 0.6398\n",
      "Epoch 546/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5200 - f1: 0.6951 - val_loss: 0.6012 - val_f1: 0.6543\n",
      "Epoch 547/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5176 - f1: 0.6963 - val_loss: 0.6005 - val_f1: 0.6426\n",
      "Epoch 548/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5228 - f1: 0.6852 - val_loss: 0.6003 - val_f1: 0.6445\n",
      "Epoch 549/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5219 - f1: 0.6867 - val_loss: 0.5990 - val_f1: 0.6438\n",
      "Epoch 550/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5230 - f1: 0.6938 - val_loss: 0.5985 - val_f1: 0.6463\n",
      "Epoch 551/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5209 - f1: 0.6906 - val_loss: 0.5982 - val_f1: 0.6534\n",
      "Epoch 552/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5195 - f1: 0.6937 - val_loss: 0.5981 - val_f1: 0.6603\n",
      "Epoch 553/5000\n",
      "7667/7667 [==============================] - 1s 156us/step - loss: 0.5153 - f1: 0.6967 - val_loss: 0.5999 - val_f1: 0.6460\n",
      "Epoch 554/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5237 - f1: 0.6903 - val_loss: 0.5976 - val_f1: 0.6486\n",
      "Epoch 555/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5215 - f1: 0.6907 - val_loss: 0.5967 - val_f1: 0.6466\n",
      "Epoch 556/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5260 - f1: 0.6955 - val_loss: 0.6001 - val_f1: 0.6443\n",
      "Epoch 557/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5223 - f1: 0.6911 - val_loss: 0.5996 - val_f1: 0.6385\n",
      "Epoch 558/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5220 - f1: 0.6905 - val_loss: 0.6001 - val_f1: 0.6402\n",
      "Epoch 559/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5180 - f1: 0.6896 - val_loss: 0.6025 - val_f1: 0.6436\n",
      "Epoch 560/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5171 - f1: 0.6929 - val_loss: 0.6002 - val_f1: 0.6467\n",
      "Epoch 561/5000\n",
      "7667/7667 [==============================] - 1s 155us/step - loss: 0.5214 - f1: 0.6900 - val_loss: 0.6002 - val_f1: 0.6385\n",
      "Epoch 562/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5172 - f1: 0.6949 - val_loss: 0.6008 - val_f1: 0.6353\n",
      "Epoch 563/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5154 - f1: 0.6935 - val_loss: 0.6003 - val_f1: 0.6533\n",
      "Epoch 564/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5233 - f1: 0.6916 - val_loss: 0.5987 - val_f1: 0.6386\n",
      "Epoch 565/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5213 - f1: 0.6971 - val_loss: 0.6007 - val_f1: 0.6355\n",
      "Epoch 566/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5216 - f1: 0.6985 - val_loss: 0.6040 - val_f1: 0.6394\n",
      "Epoch 567/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5222 - f1: 0.6865 - val_loss: 0.6003 - val_f1: 0.6405\n",
      "Epoch 568/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5186 - f1: 0.6956 - val_loss: 0.6008 - val_f1: 0.6345\n",
      "Epoch 569/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5165 - f1: 0.6954 - val_loss: 0.6017 - val_f1: 0.6397\n",
      "Epoch 570/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5214 - f1: 0.6942 - val_loss: 0.5995 - val_f1: 0.6358\n",
      "Epoch 571/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5255 - f1: 0.6952 - val_loss: 0.5998 - val_f1: 0.6361\n",
      "Epoch 572/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5223 - f1: 0.6916 - val_loss: 0.6015 - val_f1: 0.6372\n",
      "Epoch 573/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5215 - f1: 0.6933 - val_loss: 0.6002 - val_f1: 0.6249\n",
      "Epoch 574/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5168 - f1: 0.6977 - val_loss: 0.5987 - val_f1: 0.6319\n",
      "Epoch 575/5000\n",
      "7667/7667 [==============================] - 1s 135us/step - loss: 0.5261 - f1: 0.6843 - val_loss: 0.5990 - val_f1: 0.6429\n",
      "Epoch 576/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5250 - f1: 0.6872 - val_loss: 0.5972 - val_f1: 0.6385\n",
      "Epoch 577/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5229 - f1: 0.6960 - val_loss: 0.5993 - val_f1: 0.6319\n",
      "Epoch 578/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5245 - f1: 0.6949 - val_loss: 0.5991 - val_f1: 0.6326\n",
      "Epoch 579/5000\n",
      "7667/7667 [==============================] - 1s 155us/step - loss: 0.5247 - f1: 0.6861 - val_loss: 0.5965 - val_f1: 0.6406\n",
      "Epoch 580/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5162 - f1: 0.6905 - val_loss: 0.5999 - val_f1: 0.6372\n",
      "Epoch 581/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5221 - f1: 0.6949 - val_loss: 0.5973 - val_f1: 0.6466\n",
      "Epoch 582/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5185 - f1: 0.6957 - val_loss: 0.5975 - val_f1: 0.6400\n",
      "Epoch 583/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5228 - f1: 0.6925 - val_loss: 0.6011 - val_f1: 0.6415\n",
      "Epoch 584/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5202 - f1: 0.6915 - val_loss: 0.6011 - val_f1: 0.6327\n",
      "Epoch 585/5000\n",
      "7667/7667 [==============================] - 1s 155us/step - loss: 0.5258 - f1: 0.6815 - val_loss: 0.5987 - val_f1: 0.6386\n",
      "Epoch 586/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5186 - f1: 0.6971 - val_loss: 0.5991 - val_f1: 0.6352\n",
      "Epoch 587/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5252 - f1: 0.6927 - val_loss: 0.6010 - val_f1: 0.6406\n",
      "Epoch 588/5000\n",
      "7667/7667 [==============================] - 1s 158us/step - loss: 0.5183 - f1: 0.6936 - val_loss: 0.6012 - val_f1: 0.6412\n",
      "Epoch 589/5000\n",
      "7667/7667 [==============================] - 1s 152us/step - loss: 0.5209 - f1: 0.6924 - val_loss: 0.5991 - val_f1: 0.6442\n",
      "Epoch 590/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5221 - f1: 0.6891 - val_loss: 0.5993 - val_f1: 0.6402\n",
      "Epoch 591/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5205 - f1: 0.6961 - val_loss: 0.5986 - val_f1: 0.6377\n",
      "Epoch 592/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5214 - f1: 0.6862 - val_loss: 0.5989 - val_f1: 0.6370\n",
      "Epoch 593/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5199 - f1: 0.6892 - val_loss: 0.5992 - val_f1: 0.6358\n",
      "Epoch 594/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5248 - f1: 0.6866 - val_loss: 0.5981 - val_f1: 0.6408\n",
      "Epoch 595/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5217 - f1: 0.6920 - val_loss: 0.5996 - val_f1: 0.6394\n",
      "Epoch 596/5000\n",
      "7667/7667 [==============================] - 1s 136us/step - loss: 0.5161 - f1: 0.6968 - val_loss: 0.5998 - val_f1: 0.6384\n",
      "Epoch 597/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5199 - f1: 0.6873 - val_loss: 0.5986 - val_f1: 0.6359\n",
      "Epoch 598/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5241 - f1: 0.6903 - val_loss: 0.5982 - val_f1: 0.6373\n",
      "Epoch 599/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5130 - f1: 0.6985 - val_loss: 0.5998 - val_f1: 0.6380\n",
      "Epoch 600/5000\n",
      "7667/7667 [==============================] - ETA: 0s - loss: 0.5195 - f1: 0.69 - 1s 145us/step - loss: 0.5188 - f1: 0.6972 - val_loss: 0.5975 - val_f1: 0.6449\n",
      "Epoch 601/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5252 - f1: 0.6974 - val_loss: 0.5969 - val_f1: 0.6482\n",
      "Epoch 602/5000\n",
      "7667/7667 [==============================] - 1s 151us/step - loss: 0.5221 - f1: 0.6922 - val_loss: 0.5965 - val_f1: 0.6339\n",
      "Epoch 603/5000\n",
      "7667/7667 [==============================] - 1s 154us/step - loss: 0.5172 - f1: 0.6907 - val_loss: 0.5967 - val_f1: 0.6409\n",
      "Epoch 604/5000\n",
      "7667/7667 [==============================] - 1s 158us/step - loss: 0.5197 - f1: 0.6941 - val_loss: 0.6001 - val_f1: 0.6240\n",
      "Epoch 605/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5218 - f1: 0.6908 - val_loss: 0.5968 - val_f1: 0.6408\n",
      "Epoch 606/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5219 - f1: 0.6904 - val_loss: 0.5982 - val_f1: 0.6457\n",
      "Epoch 607/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5257 - f1: 0.6878 - val_loss: 0.5983 - val_f1: 0.6343\n",
      "Epoch 608/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5162 - f1: 0.6918 - val_loss: 0.5986 - val_f1: 0.6343\n",
      "Epoch 609/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5213 - f1: 0.6975 - val_loss: 0.6006 - val_f1: 0.6402\n",
      "Epoch 610/5000\n",
      "7667/7667 [==============================] - 1s 158us/step - loss: 0.5163 - f1: 0.6934 - val_loss: 0.5993 - val_f1: 0.6303\n",
      "Epoch 611/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5127 - f1: 0.7000 - val_loss: 0.5979 - val_f1: 0.6405\n",
      "Epoch 612/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5206 - f1: 0.6985 - val_loss: 0.5968 - val_f1: 0.6446\n",
      "Epoch 613/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5202 - f1: 0.6933 - val_loss: 0.5980 - val_f1: 0.6431\n",
      "Epoch 614/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5220 - f1: 0.6952 - val_loss: 0.6004 - val_f1: 0.6374\n",
      "Epoch 615/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5221 - f1: 0.6936 - val_loss: 0.5978 - val_f1: 0.6420\n",
      "Epoch 616/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5219 - f1: 0.6956 - val_loss: 0.5981 - val_f1: 0.6361\n",
      "Epoch 617/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5163 - f1: 0.6956 - val_loss: 0.5971 - val_f1: 0.6327\n",
      "Epoch 618/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5190 - f1: 0.6931 - val_loss: 0.5962 - val_f1: 0.6300\n",
      "Epoch 619/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5217 - f1: 0.6942 - val_loss: 0.5975 - val_f1: 0.6284\n",
      "Epoch 620/5000\n",
      "7667/7667 [==============================] - 1s 155us/step - loss: 0.5177 - f1: 0.6976 - val_loss: 0.5988 - val_f1: 0.6486\n",
      "Epoch 621/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5138 - f1: 0.6979 - val_loss: 0.5985 - val_f1: 0.6460\n",
      "Epoch 622/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5229 - f1: 0.6905 - val_loss: 0.5992 - val_f1: 0.6346\n",
      "Epoch 623/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5204 - f1: 0.6931 - val_loss: 0.5971 - val_f1: 0.6435\n",
      "Epoch 624/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5210 - f1: 0.6905 - val_loss: 0.5991 - val_f1: 0.6335\n",
      "Epoch 625/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5164 - f1: 0.6977 - val_loss: 0.5978 - val_f1: 0.6320\n",
      "Epoch 626/5000\n",
      "7667/7667 [==============================] - 1s 137us/step - loss: 0.5185 - f1: 0.6966 - val_loss: 0.5962 - val_f1: 0.6301\n",
      "Epoch 627/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5183 - f1: 0.6892 - val_loss: 0.5981 - val_f1: 0.6489\n",
      "Epoch 628/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5188 - f1: 0.6962 - val_loss: 0.5987 - val_f1: 0.6359\n",
      "Epoch 629/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5189 - f1: 0.6929 - val_loss: 0.5992 - val_f1: 0.6433\n",
      "Epoch 630/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5227 - f1: 0.6895 - val_loss: 0.5976 - val_f1: 0.6487\n",
      "Epoch 631/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5205 - f1: 0.6939 - val_loss: 0.5990 - val_f1: 0.6454\n",
      "Epoch 632/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5153 - f1: 0.6988 - val_loss: 0.5994 - val_f1: 0.6443\n",
      "Epoch 633/5000\n",
      "7667/7667 [==============================] - 1s 146us/step - loss: 0.5167 - f1: 0.6938 - val_loss: 0.5984 - val_f1: 0.6384\n",
      "Epoch 634/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5187 - f1: 0.6978 - val_loss: 0.5990 - val_f1: 0.6421\n",
      "Epoch 635/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5197 - f1: 0.7002 - val_loss: 0.5974 - val_f1: 0.6394\n",
      "Epoch 636/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5186 - f1: 0.7020 - val_loss: 0.5962 - val_f1: 0.6440\n",
      "Epoch 637/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5196 - f1: 0.6891 - val_loss: 0.6001 - val_f1: 0.6298\n",
      "Epoch 638/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5182 - f1: 0.6978 - val_loss: 0.5976 - val_f1: 0.6381\n",
      "Epoch 639/5000\n",
      "7667/7667 [==============================] - 1s 167us/step - loss: 0.5157 - f1: 0.6914 - val_loss: 0.6019 - val_f1: 0.6365\n",
      "Epoch 640/5000\n",
      "7667/7667 [==============================] - 1s 157us/step - loss: 0.5195 - f1: 0.6914 - val_loss: 0.5977 - val_f1: 0.6341\n",
      "Epoch 641/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5134 - f1: 0.6947 - val_loss: 0.5992 - val_f1: 0.6514\n",
      "Epoch 642/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5220 - f1: 0.6922 - val_loss: 0.5985 - val_f1: 0.6357\n",
      "Epoch 643/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5168 - f1: 0.6960 - val_loss: 0.5988 - val_f1: 0.6416\n",
      "Epoch 644/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5195 - f1: 0.6917 - val_loss: 0.5980 - val_f1: 0.6406\n",
      "Epoch 645/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5189 - f1: 0.6933 - val_loss: 0.5964 - val_f1: 0.6263\n",
      "Epoch 646/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5190 - f1: 0.6916 - val_loss: 0.5962 - val_f1: 0.6389\n",
      "Epoch 647/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5194 - f1: 0.6978 - val_loss: 0.5948 - val_f1: 0.6348\n",
      "Epoch 648/5000\n",
      "7667/7667 [==============================] - 1s 152us/step - loss: 0.5164 - f1: 0.6987 - val_loss: 0.5977 - val_f1: 0.6365\n",
      "Epoch 649/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5247 - f1: 0.6897 - val_loss: 0.5976 - val_f1: 0.6373\n",
      "Epoch 650/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5152 - f1: 0.6989 - val_loss: 0.5956 - val_f1: 0.6320\n",
      "Epoch 651/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5162 - f1: 0.6949 - val_loss: 0.5964 - val_f1: 0.6398\n",
      "Epoch 652/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5124 - f1: 0.6929 - val_loss: 0.5973 - val_f1: 0.6433\n",
      "Epoch 653/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5206 - f1: 0.6903 - val_loss: 0.5965 - val_f1: 0.6372\n",
      "Epoch 654/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5199 - f1: 0.6922 - val_loss: 0.5959 - val_f1: 0.6369\n",
      "Epoch 655/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5203 - f1: 0.6891 - val_loss: 0.5975 - val_f1: 0.6427\n",
      "Epoch 656/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5170 - f1: 0.6905 - val_loss: 0.5974 - val_f1: 0.6341\n",
      "Epoch 657/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5177 - f1: 0.6981 - val_loss: 0.5960 - val_f1: 0.6361\n",
      "Epoch 658/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5200 - f1: 0.6880 - val_loss: 0.5948 - val_f1: 0.6234\n",
      "Epoch 659/5000\n",
      "7667/7667 [==============================] - 1s 145us/step - loss: 0.5135 - f1: 0.7004 - val_loss: 0.5977 - val_f1: 0.6374\n",
      "Epoch 660/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5176 - f1: 0.6909 - val_loss: 0.5959 - val_f1: 0.6212\n",
      "Epoch 661/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5157 - f1: 0.7014 - val_loss: 0.5977 - val_f1: 0.6479\n",
      "Epoch 662/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5181 - f1: 0.6937 - val_loss: 0.5935 - val_f1: 0.6391\n",
      "Epoch 663/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5169 - f1: 0.6930 - val_loss: 0.5923 - val_f1: 0.6389\n",
      "Epoch 664/5000\n",
      "7667/7667 [==============================] - 1s 150us/step - loss: 0.5201 - f1: 0.6930 - val_loss: 0.5930 - val_f1: 0.6313\n",
      "Epoch 665/5000\n",
      "7667/7667 [==============================] - 1s 138us/step - loss: 0.5164 - f1: 0.7009 - val_loss: 0.5954 - val_f1: 0.6392\n",
      "Epoch 666/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5201 - f1: 0.6927 - val_loss: 0.5967 - val_f1: 0.6463\n",
      "Epoch 667/5000\n",
      "7667/7667 [==============================] - 1s 153us/step - loss: 0.5170 - f1: 0.6953 - val_loss: 0.5939 - val_f1: 0.6435\n",
      "Epoch 668/5000\n",
      "7667/7667 [==============================] - 1s 164us/step - loss: 0.5179 - f1: 0.6982 - val_loss: 0.5949 - val_f1: 0.6395\n",
      "Epoch 669/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5234 - f1: 0.6919 - val_loss: 0.5945 - val_f1: 0.6367\n",
      "Epoch 670/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5150 - f1: 0.6968 - val_loss: 0.5941 - val_f1: 0.6419\n",
      "Epoch 671/5000\n",
      "7667/7667 [==============================] - 1s 139us/step - loss: 0.5233 - f1: 0.6952 - val_loss: 0.5957 - val_f1: 0.6457\n",
      "Epoch 672/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5220 - f1: 0.6934 - val_loss: 0.5926 - val_f1: 0.6422\n",
      "Epoch 673/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5209 - f1: 0.6926 - val_loss: 0.5927 - val_f1: 0.6421\n",
      "Epoch 674/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5186 - f1: 0.6960 - val_loss: 0.5939 - val_f1: 0.6343\n",
      "Epoch 675/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5138 - f1: 0.7025 - val_loss: 0.5944 - val_f1: 0.6400\n",
      "Epoch 676/5000\n",
      "7667/7667 [==============================] - 1s 148us/step - loss: 0.5186 - f1: 0.6950 - val_loss: 0.5948 - val_f1: 0.6370\n",
      "Epoch 677/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5152 - f1: 0.6946 - val_loss: 0.5928 - val_f1: 0.6600\n",
      "Epoch 678/5000\n",
      "7667/7667 [==============================] - 1s 159us/step - loss: 0.5180 - f1: 0.6886 - val_loss: 0.5958 - val_f1: 0.6362\n",
      "Epoch 679/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5236 - f1: 0.6898 - val_loss: 0.5940 - val_f1: 0.6451\n",
      "Epoch 680/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5208 - f1: 0.6916 - val_loss: 0.5950 - val_f1: 0.6503\n",
      "Epoch 681/5000\n",
      "7667/7667 [==============================] - 1s 144us/step - loss: 0.5166 - f1: 0.6977 - val_loss: 0.5965 - val_f1: 0.6308\n",
      "Epoch 682/5000\n",
      "7667/7667 [==============================] - 1s 149us/step - loss: 0.5163 - f1: 0.6942 - val_loss: 0.5966 - val_f1: 0.6232\n",
      "Epoch 683/5000\n",
      "7667/7667 [==============================] - 1s 143us/step - loss: 0.5200 - f1: 0.6923 - val_loss: 0.5947 - val_f1: 0.6459\n",
      "Epoch 684/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5149 - f1: 0.6971 - val_loss: 0.5963 - val_f1: 0.6423\n",
      "Epoch 685/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5147 - f1: 0.6992 - val_loss: 0.5945 - val_f1: 0.6466\n",
      "Epoch 686/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5128 - f1: 0.6989 - val_loss: 0.5945 - val_f1: 0.6395\n",
      "Epoch 687/5000\n",
      "7667/7667 [==============================] - 1s 147us/step - loss: 0.5224 - f1: 0.6941 - val_loss: 0.5936 - val_f1: 0.6463\n",
      "Epoch 688/5000\n",
      "7667/7667 [==============================] - ETA: 0s - loss: 0.5183 - f1: 0.69 - 1s 141us/step - loss: 0.5167 - f1: 0.6975 - val_loss: 0.5927 - val_f1: 0.6491\n",
      "Epoch 689/5000\n",
      "7667/7667 [==============================] - 1s 141us/step - loss: 0.5161 - f1: 0.6991 - val_loss: 0.5966 - val_f1: 0.6341\n",
      "Epoch 690/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5159 - f1: 0.7014 - val_loss: 0.5950 - val_f1: 0.6381\n",
      "Epoch 691/5000\n",
      "7667/7667 [==============================] - 1s 142us/step - loss: 0.5143 - f1: 0.6982 - val_loss: 0.5923 - val_f1: 0.6356\n",
      "Epoch 692/5000\n",
      "7667/7667 [==============================] - 1s 140us/step - loss: 0.5139 - f1: 0.6932 - val_loss: 0.5925 - val_f1: 0.6385\n",
      "Epoch 693/5000\n",
      "1664/7667 [=====>........................] - ETA: 0s - loss: 0.5379 - f1: 0.6722"
     ]
    }
   ],
   "source": [
    "# train model on data\n",
    "eth_history = eth_model.fit(bin_X_train, bin_y_train,\n",
    "                            epochs=epochs, batch_size=batch_size,\n",
    "                            verbose=1, validation_data=(bin_X_val, bin_y_val),\n",
    "                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
