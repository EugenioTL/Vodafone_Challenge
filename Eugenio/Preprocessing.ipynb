{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = 202\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Import the train set and test set\n",
    "train_data = pd.read_csv(\"polimi_dataset_challenge_train_v1.csv\", delimiter=\",\")\n",
    "test_data = pd.read_csv(\"polimi_dataset_challenge_test_to_predict_v1.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_costumer_age(dataset):\n",
    "    #Take all unique Cosumer_Age, assigns to each age alphabetically ordered a mean age\n",
    "    customer_age_sort = sorted(dataset['CustomerAge'].dropna().unique())\n",
    "\n",
    "    mapping = {}\n",
    "    for idx, val in enumerate(customer_age_sort):\n",
    "        mapping[val] = int(15+idx*10)\n",
    "        \n",
    "    ages = dataset['CustomerAge']\n",
    "    ages.replace(mapping, inplace=True)\n",
    "\n",
    "    #print(mapping, regions)\n",
    "    ages = np.asarray(ages)\n",
    "    ages = pd.DataFrame({'CustomerAge': ages})\n",
    "    \n",
    "     # Remove the previous CustomerAge and then insert the new CustomerAge\n",
    "    dataset = dataset.drop('CustomerAge', axis=1)\n",
    "    dataset = dataset.join(ages)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_region(dataset):\n",
    "    #Take all unique Regions, assigns to each region alphabetically ordered a monotonic growing number\n",
    "    regions_sort = sorted(dataset['Region'].dropna().unique())\n",
    "    #regions_len = len(regions_sort) #20 Regions\n",
    "\n",
    "    mapping = {}\n",
    "    for idx, val in enumerate(regions_sort):\n",
    "        mapping[val] = int(idx)\n",
    "\n",
    "    regions = dataset['Region']\n",
    "    regions.replace(mapping, inplace=True)\n",
    "\n",
    "    #print(mapping, regions)\n",
    "    regions = np.asarray(regions)\n",
    "    regions = pd.DataFrame({'Region': regions})\n",
    "    \n",
    "    # Remove the previous Region columns and then insert the new Region\n",
    "    dataset = dataset.drop('Region', axis=1)\n",
    "    dataset = dataset.join(regions)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_province(dataset):\n",
    "    #Take all unique Provinces, assigns to each province alphabetically ordered a monotonic growing number\n",
    "    provinces_sort = sorted(dataset['Province'].dropna().unique())\n",
    "    #provinces_len = len(provinces_sort) #110 Provinces\n",
    "\n",
    "    mapping = {}\n",
    "    for idx, val in enumerate(provinces_sort):\n",
    "        mapping[val] = idx\n",
    "\n",
    "    provinces = dataset['Province']\n",
    "    provinces.replace(mapping, inplace=True)\n",
    "\n",
    "\n",
    "    #print(provinces_sort, provinces_len)\n",
    "    #print(mapping, provinces)\n",
    "    provinces = np.asarray(provinces)\n",
    "    provinces = pd.DataFrame({'Province': provinces})\n",
    "    \n",
    "    # Remove the previous Province columns and then insert the new Province\n",
    "    dataset = dataset.drop('Province', axis=1)\n",
    "    dataset = dataset.join(provinces)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_product(dataset):\n",
    "    if('Product' in dataset.columns):\n",
    "        #Take all unique Products, assigns to each product alphabetically ordered a monotonic growing number\n",
    "        products_sort = sorted(dataset['Product'].dropna().unique())\n",
    "\n",
    "        mapping = {}\n",
    "        for idx, val in enumerate(products_sort):\n",
    "            mapping[val] = int(idx)\n",
    "\n",
    "        products = dataset['Product']\n",
    "        products.replace(mapping, inplace=True)\n",
    "\n",
    "        #print(mapping, products)\n",
    "        products = np.asarray(products)\n",
    "        products = pd.DataFrame({'Product': products})\n",
    "\n",
    "        # Remove the previous Product columns and then insert the newProduct\n",
    "        dataset = dataset.drop('Product', axis=1)\n",
    "        dataset = dataset.join(products)\n",
    "        print(mapping)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_useless_columns(dataset):\n",
    "    if('DataAllowanceOneShot' in dataset.columns and 'EstimatedDevicePrice' in dataset.columns and 'ZipCode' in dataset.columns):\n",
    "        dataset = dataset.drop('DataAllowanceOneShot', axis=1)\n",
    "        dataset = dataset.drop('EstimatedDevicePrice', axis=1)\n",
    "        dataset = dataset.drop('ZipCode', axis=1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_modified_sample(dataset):\n",
    "    modified = []\n",
    "    for i in dataset.isnull().any(axis=1):\n",
    "        if(i):\n",
    "            modified.append(1)\n",
    "        else:\n",
    "            modified.append(0)\n",
    "    modified = np.asarray(modified)\n",
    "    modified = pd.DataFrame({'IsModified': modified})\n",
    "    dataset = dataset.join(modified)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_set(dataset):\n",
    "    dataset = drop_useless_columns(dataset)\n",
    "    dataset = merge_duration_count(dataset)\n",
    "    dataset = add_modified_sample(dataset)\n",
    "    dataset = normalize_costumer_age(dataset)\n",
    "    dataset = normalize_region(dataset)\n",
    "    dataset = normalize_province(dataset)\n",
    "    dataset = normalize_product(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Non-Customer': 0, 'V-Auto': 1, 'V-Bag': 2, 'V-Pet': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'DeviceFlag4G', 'DataArpu', 'DataAllowanceContinuous',\n",
       "       'DeviceFlagSmartphone', 'MonthlyVoiceTrafficCount',\n",
       "       'MonthlySMSTrafficCount', 'MonthlyDataTraffic', 'CustomerGender',\n",
       "       'CustomerExpatriate', 'ChurnScore', 'AirportConnectionsDuration',\n",
       "       'AirportConnectionsCount', 'StationConnectionsDuration',\n",
       "       'StationConnectionsCount', 'ParkingConnectionsDuration',\n",
       "       'ParkingConnectionsCount', 'File-Transfer', 'Games',\n",
       "       'Instant-Messaging-Applications', 'Mail', 'Music-Streaming',\n",
       "       'Network-Operation', 'P2P-Applications', 'Security',\n",
       "       'Streaming-Applications', 'Terminals', 'Unclassified', 'VoIP',\n",
       "       'Web-Applications', 'ConnectionsDuration', 'ConnectionsCount',\n",
       "       'IsModified', 'CustomerAge', 'Region', 'Province', 'Product'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = normalize_data_set(train_data)\n",
    "test_data = normalize_data_set(test_data)\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train_data\n",
    "testset = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def fill_nan(field, datap):\n",
    "    data = datap\n",
    "    nnan = data.isnull()[field].sum()\n",
    "    field_id = data[['ID',field]]\n",
    "    field_count = field_id.groupby(field).count()\n",
    "    field_per = round(field_count/(len(data[field].dropna(axis=0)))*100,5)\n",
    "    field_2badd = round(field_per/100*nnan,5)\n",
    "    \n",
    "#     print(len(field_2badd))\n",
    "#     print(field_2badd)\n",
    "#     print(field_2badd.sum())\n",
    "    \n",
    "    le = len(data)\n",
    "    ct = field_2badd.values[0]\n",
    "    j = 0\n",
    "    for i in range(le):\n",
    "        if(math.isnan(data[field][i])):\n",
    "            #print(\"2badd: \" + str(field_2badd.index[j]))\n",
    "            data[field][i] = field_2badd.index[j]\n",
    "            ct -=1\n",
    "            if(ct <= 0.0 and j < len(field_2badd)):\n",
    "                j += 1\n",
    "                #print(\"ct: \" + str(ct))\n",
    "                ct = field_2badd.values[j]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    16.0\n",
       " 1     0.0\n",
       " 2     0.0\n",
       " 3     8.0\n",
       " 4    19.0\n",
       " Name: Region, dtype: float64, 0    12.0\n",
       " 1     3.0\n",
       " 2    15.0\n",
       " 3     0.0\n",
       " 4     7.0\n",
       " Name: Region, dtype: float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = fill_nan('Region', trainset)\n",
    "testset = fill_nan('Region', testset)\n",
    "trainset.Region.head(),testset.Region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9567, 35)\n",
      "count    9567.000000\n",
      "mean        9.138392\n",
      "std         4.995239\n",
      "min         0.000000\n",
      "25%         6.000000\n",
      "50%         8.000000\n",
      "75%        13.000000\n",
      "max        19.000000\n",
      "Name: Region, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(trainset.shape)\n",
    "print(trainset['Region'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 34)\n",
      "count    3190.000000\n",
      "mean        9.228527\n",
      "std         5.073446\n",
      "min         0.000000\n",
      "25%         6.000000\n",
      "50%         8.000000\n",
      "75%        13.000000\n",
      "max        19.000000\n",
      "Name: Region, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(testset.shape)\n",
    "print(testset['Region'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_region(datap):\n",
    "    data = datap\n",
    "    region_ohe = data['Region']\n",
    "\n",
    "    north_regions = [4,5,7,8,11,17,18,19]\n",
    "    middle_regions = [0,6,9,10,15,16]\n",
    "    suoth_regions = [1,2,3,12,13,14]\n",
    "    regions_cluster = []\n",
    "\n",
    "    for i in region_ohe.values:\n",
    "        if i in nord_regions:\n",
    "            regions_cluster.append(0)\n",
    "        elif i in centro_regions:\n",
    "            regions_cluster.append(1)   \n",
    "        elif i in sud_regions:\n",
    "            regions_cluster.append(2)\n",
    "        else:\n",
    "            regions_cluster.append(np.nan)\n",
    "    \n",
    "    regions_cluster = np.asarray(regions_cluster)\n",
    "    regions_cluster = pd.DataFrame({'Regions_Cluster' : regions_cluster})\n",
    "\n",
    "    data = data.join(regions_cluster)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    16.0\n",
       " 1     0.0\n",
       " 2     0.0\n",
       " 3     8.0\n",
       " 4    19.0\n",
       " Name: Region, dtype: float64, 0    12.0\n",
       " 1     3.0\n",
       " 2    15.0\n",
       " 3     0.0\n",
       " 4     7.0\n",
       " Name: Region, dtype: float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = ohe_region(trainset)\n",
    "testset = ohe_region(testset)\n",
    "trainset.Region.head(),testset.Region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9567, 38)\n",
      "count    9567.000000\n",
      "mean        0.477057\n",
      "std         0.499499\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: North_Region, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(trainset.shape)\n",
    "print(trainset['North_Region'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 37)\n",
      "count    3190.000000\n",
      "mean        0.483699\n",
      "std         0.499813\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: North_Region, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(testset.shape)\n",
    "print(testset['North_Region'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5628    93.0\n",
       " 6680    42.0\n",
       " 3710    42.0\n",
       " 8720    71.0\n",
       " 5351    71.0\n",
       " Name: Province, dtype: float64, 59       NaN\n",
       " 189     42.0\n",
       " 2722    93.0\n",
       " 3029    71.0\n",
       " 2721    24.0\n",
       " Name: Province, dtype: float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = trainset.sort_values(by='Region')\n",
    "trainset['Province'] = trainset['Province'].fillna(method='ffill')\n",
    "testset = testset.sort_values(by='Region')\n",
    "testset['Province'] = testset['Province'].fillna(method='ffill')\n",
    "trainset['Province'].head(5),testset['Province'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9567, 38)\n",
      "count    9567.000000\n",
      "mean       56.903104\n",
      "std        31.357100\n",
      "min         0.000000\n",
      "25%        27.000000\n",
      "50%        58.000000\n",
      "75%        84.000000\n",
      "max       109.000000\n",
      "Name: Province, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(trainset.shape)\n",
    "print(trainset['Province'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 37)\n",
      "count    3189.000000\n",
      "mean       56.803073\n",
      "std        31.752841\n",
      "min         0.000000\n",
      "25%        27.000000\n",
      "50%        58.000000\n",
      "75%        84.000000\n",
      "max       109.000000\n",
      "Name: Province, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(testset.shape)\n",
    "print(testset['Province'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomerAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5628    45.0\n",
       " 6680    45.0\n",
       " 3710    45.0\n",
       " 8720    45.0\n",
       " 5351    25.0\n",
       " Name: CustomerAge, dtype: float64, (3190,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = fill_nan('CustomerAge', trainset)\n",
    "\n",
    "# test_data = normalize_data_set(pd.read_csv(\"testset.csv\", delimiter=\",\"))\n",
    "# testset = test_data\n",
    "testset = fill_nan('CustomerAge', testset)\n",
    "trainset.CustomerAge.head(), testset.CustomerAge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                  0\n",
       "DeviceFlag4G                        0\n",
       "DataArpu                          757\n",
       "DataAllowanceContinuous           388\n",
       "DeviceFlagSmartphone                0\n",
       "MonthlyVoiceTrafficCount          110\n",
       "MonthlySMSTrafficCount            110\n",
       "MonthlyDataTraffic                110\n",
       "CustomerGender                      0\n",
       "CustomerExpatriate                  0\n",
       "ChurnScore                        303\n",
       "AirportConnectionsDuration          0\n",
       "AirportConnectionsCount             0\n",
       "StationConnectionsDuration          0\n",
       "StationConnectionsCount             0\n",
       "ParkingConnectionsDuration          0\n",
       "ParkingConnectionsCount             0\n",
       "File-Transfer                       0\n",
       "Games                               0\n",
       "Instant-Messaging-Applications      0\n",
       "Mail                                0\n",
       "Music-Streaming                     0\n",
       "Network-Operation                   0\n",
       "P2P-Applications                    0\n",
       "Security                            0\n",
       "Streaming-Applications              0\n",
       "Terminals                           0\n",
       "Unclassified                        0\n",
       "VoIP                                0\n",
       "Web-Applications                    0\n",
       "IsModified                          0\n",
       "CustomerAge                         0\n",
       "Region                              0\n",
       "Province                            1\n",
       "North_Region                        0\n",
       "Middle_Region                       0\n",
       "South_Region                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9567, 38)\n",
      "count    9567.000000\n",
      "mean       44.778405\n",
      "std        14.593704\n",
      "min        15.000000\n",
      "25%        35.000000\n",
      "50%        45.000000\n",
      "75%        55.000000\n",
      "max        85.000000\n",
      "Name: CustomerAge, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(trainset.shape)\n",
    "print(trainset['CustomerAge'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 37)\n",
      "count    3190.000000\n",
      "mean       44.398119\n",
      "std        14.401887\n",
      "min        15.000000\n",
      "25%        35.000000\n",
      "50%        45.000000\n",
      "75%        55.000000\n",
      "max        85.000000\n",
      "Name: CustomerAge, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(testset.shape)\n",
    "print(testset['CustomerAge'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_customer_age(datap):\n",
    "    data = datap\n",
    "    age_ohe = data['CustomerAge']\n",
    "\n",
    "    young_customer = [5,15,25]\n",
    "    young = []\n",
    "    adult_customer = [35,45,55]\n",
    "    adult = []\n",
    "    old_customer = [65,75,85]\n",
    "    old = []\n",
    "\n",
    "    for i in age_ohe.values:\n",
    "        if i in young_customer:\n",
    "            young.append(1)\n",
    "            adult.append(0)\n",
    "            old.append(0)\n",
    "        elif i in adult_customer:\n",
    "            young.append(0)\n",
    "            adult.append(1)\n",
    "            old.append(0)    \n",
    "        elif i in old_customer:\n",
    "            young.append(0)\n",
    "            adult.append(0)\n",
    "            old.append(1)\n",
    "        else:\n",
    "            young.append(np.nan)\n",
    "            adult.append(np.nan)\n",
    "            old.append(np.nan)\n",
    "\n",
    "    yo = pd.DataFrame({'Young_Customer' : young})\n",
    "    ad = pd.DataFrame({'Adult_Customer' : adult})\n",
    "    ol = pd.DataFrame({'Old_Customer' : old})\n",
    "\n",
    "    data = data.join(yo)\n",
    "    data = data.join(ad)\n",
    "    data = data.join(ol)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5628    45.0\n",
       " 6680    45.0\n",
       " 3710    45.0\n",
       " 8720    45.0\n",
       " 5351    25.0\n",
       " Name: CustomerAge, dtype: float64, 59      65.0\n",
       " 189     55.0\n",
       " 2722    25.0\n",
       " 3029    55.0\n",
       " 2721    25.0\n",
       " Name: CustomerAge, dtype: float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = ohe_customer_age(trainset)\n",
    "testset = ohe_customer_age(testset)\n",
    "trainset.CustomerAge.head(),testset.CustomerAge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9567, 41)\n",
      "count    9567.000000\n",
      "mean        0.149890\n",
      "std         0.356982\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "Name: Old_Customer, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(trainset.shape)\n",
    "print(trainset['Old_Customer'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 40)\n",
      "count    3190.000000\n",
      "mean        0.141693\n",
      "std         0.348789\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "Name: Old_Customer, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(testset.shape)\n",
    "print(testset['Old_Customer'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MonthlyVoiceTrafficCount - MonthlySMSTrafficCount - MonthlyDataTraffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = trainset.fillna(trainset.mean())\n",
    "testset = testset.fillna(testset.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export .csv document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.to_csv('train_rodolfo.csv', index = False, encoding='utf-8')\n",
    "testset.to_csv('test_rodolfo.csv', index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9567, 41)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3190, 40)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9567"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.North_Region.sum()+trainset.Middle_Region.sum()+trainset.South_Region.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
