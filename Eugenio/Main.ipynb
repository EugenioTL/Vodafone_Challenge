{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = 202\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train set and test set\n",
    "train_data = pd.read_csv(\"train_rodolfo.csv\", delimiter=\",\")\n",
    "test_data = pd.read_csv(\"test_rodolfo.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = train_data.drop('DataArpu', axis=1)\n",
    "train_data = train_data.drop('ID', axis=1)\n",
    "# Sort the dataset\n",
    "train_data = train_data.iloc[np.random.permutation(len(train_data))]\n",
    "train_data = train_data[['DeviceFlag4G', 'DataArpu', 'DataAllowanceContinuous',\n",
    "       'DeviceFlagSmartphone', 'MonthlyVoiceTrafficCount',\n",
    "       'MonthlySMSTrafficCount', 'MonthlyDataTraffic', 'CustomerGender',\n",
    "       'CustomerExpatriate', 'ChurnScore', 'AirportConnectionsDuration',\n",
    "       'AirportConnectionsCount', 'StationConnectionsDuration',\n",
    "       'StationConnectionsCount', 'ParkingConnectionsDuration',\n",
    "       'ParkingConnectionsCount', 'File-Transfer', 'Games',\n",
    "       'Instant-Messaging-Applications', 'Mail', 'Music-Streaming',\n",
    "       'Network-Operation', 'P2P-Applications', 'Security',\n",
    "       'Streaming-Applications', 'Terminals', 'Unclassified', 'VoIP',\n",
    "       'Web-Applications', 'IsModified', 'CustomerAge', 'Region', 'Province',\n",
    "       'Product']]\n",
    "train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.asarray(train_data)\n",
    "\n",
    "X = array[:,0:train_data.shape[1]-1]\n",
    "X = np.asarray(X)\n",
    "Y = array[:,train_data.shape[1]-1]\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "chi2_test = SelectKBest(score_func=chi2, k=27)\n",
    "fit = chi2_test.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DeviceFlag4G', 'DataArpu', 'DataAllowanceContinuous',\n",
       "       'DeviceFlagSmartphone', 'MonthlyVoiceTrafficCount',\n",
       "       'MonthlyDataTraffic', 'CustomerGender', 'CustomerExpatriate',\n",
       "       'AirportConnectionsDuration', 'AirportConnectionsCount',\n",
       "       'StationConnectionsDuration', 'StationConnectionsCount',\n",
       "       'ParkingConnectionsDuration', 'ParkingConnectionsCount',\n",
       "       'File-Transfer', 'Instant-Messaging-Applications', 'Mail',\n",
       "       'Music-Streaming', 'P2P-Applications', 'Security',\n",
       "       'Streaming-Applications', 'Terminals', 'Web-Applications', 'IsModified',\n",
       "       'CustomerAge', 'Region', 'Province'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[chi2_test.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4e+01 3.2e+00 2.6e+01 1.4e+01 9.0e+00 4.3e-01 8.2e+00 9.7e+01 3.1e+01\n",
      " 1.6e+00 3.4e+01 3.5e+01 3.9e+01 3.5e+01 6.4e+01 6.5e+01 1.1e+01 1.3e-01\n",
      " 3.6e+00 2.2e+00 9.4e+00 2.3e-01 5.7e+00 3.0e+00 2.5e+00 2.0e+00 8.8e-01\n",
      " 4.5e-01 6.9e+00 5.5e+02 7.5e+01 7.0e+01 2.1e+02]\n"
     ]
    }
   ],
   "source": [
    "# summarize scores\n",
    "np.set_printoptions(precision=1)\n",
    "print(fit.scores_)\n",
    "#features = fit.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_split(data):\n",
    "    \n",
    "    features = data[train_data.columns[chi2_test.get_support(indices=True)]]\n",
    "    labels = data['Product']\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(features, labels, val_samples, test_samples):\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels =np.asarray(labels)\n",
    "    \n",
    "    X_test = features[0:test_samples]\n",
    "    y_test = labels[0:test_samples]\n",
    "\n",
    "    X_val = features[test_samples:test_samples + val_samples]\n",
    "    y_val = labels[test_samples:test_samples + val_samples]\n",
    "\n",
    "    X_train = features[test_samples + val_samples:]\n",
    "    y_train = labels[test_samples + val_samples:]\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat, train_label = features_labels_split(train_data)\n",
    "\n",
    "num_val_samples = 0\n",
    "num_test_samples = 950\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = train_test_validation_split(train_feat, train_label, num_val_samples, num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the default models to select the best one  \n",
    "# The commented classifiers are weak\n",
    "dtc = DecisionTreeClassifier()\n",
    "bnb = BernoulliNB()\n",
    "xtc = ExtraTreesClassifier()\n",
    "nb = GaussianNB()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "lr = LogisticRegression()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "ada = AdaBoostClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "#gpc = GaussianProcessClassifier() #Too fucking slow\n",
    "perc = Perceptron()\n",
    "paggr = PassiveAggressiveClassifier()\n",
    "svc = SVC()\n",
    "lsvc = LinearSVC()\n",
    "sgd = SGDClassifier()\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=3, learning_rate=0.09, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Append all the models into an array\n",
    "models = []\n",
    "models.append(('XGB', xgb))\n",
    "models.append(('SGD', sgd))\n",
    "models.append(('SVC', svc))\n",
    "models.append(('LSVC', lsvc))\n",
    "models.append(('PAGGR', paggr))\n",
    "models.append(('PERC', perc))\n",
    "models.append(('LR', lr))\n",
    "models.append(('LDA', lda))\n",
    "models.append(('KNN', knn))\n",
    "models.append(('DTC', dtc))\n",
    "models.append(('NB', nb))\n",
    "models.append(('GBC', gbc))\n",
    "models.append(('RF', rf))\n",
    "models.append(('ADA', ada))\n",
    "models.append(('QDA', qda))\n",
    "models.append(('BNB', bnb))\n",
    "models.append(('XTC', xtc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: 0.589 (0.020)\n",
      "SGD: 0.474 (0.121)\n",
      "SVC: 0.558 (0.020)\n",
      "LSVC: 0.465 (0.118)\n",
      "PAGGR: 0.413 (0.132)\n",
      "PERC: 0.547 (0.031)\n",
      "LR: 0.565 (0.018)\n",
      "LDA: 0.562 (0.020)\n",
      "KNN: 0.530 (0.013)\n",
      "DTC: 0.470 (0.015)\n",
      "NB: 0.517 (0.017)\n",
      "GBC: 0.590 (0.020)\n",
      "RF: 0.566 (0.019)\n",
      "ADA: 0.578 (0.017)\n",
      "QDA: 0.526 (0.019)\n",
      "BNB: 0.501 (0.024)\n",
      "XTC: 0.562 (0.016)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='f1_micro', n_jobs=-1)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "fig.suptitle('Algorithm Comparison', fontsize=24)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.boxplot(results)\n",
    "plt.ylim([0.40,0.70])\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing best features\n",
    "Before starting the tuning phase, we chose the best number of features for each classifier and we plotted the best (mean) performances that we could observe performing a complete exploration of all the possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NB, Avg_Score: 1.000, Num_Feat: 2\n",
      "Model: RF, Avg_Score: 1.000, Num_Feat: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []\n",
    "# models.append(('LR', lr, 'Yellow'))\n",
    "#models.append(('LDA', lda, 'Blue'))\n",
    "# models.append(('KNN', knn, 'Green'))\n",
    "models.append(('NB', nb, 'Black'))\n",
    "# models.append(('GBC', gbc, 'Orange'))\n",
    "models.append(('RF', rf, 'Red'))\n",
    "# models.append(('ADA', ada, 'Grey'))\n",
    "# models.append(('QDA', qda, 'Purple'))\n",
    "#models.append(('XGB', xgb, 'Cyan'))\n",
    "#models.append(('XTC', xtc, 'Magenta'))\n",
    "\n",
    "feat_range = X_train.shape[1]\n",
    "\n",
    "n = ['NB','XGB']\n",
    "n_number = np.arange(2,feat_range,1)\n",
    "# Transforming the lists into array for plotting\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title('Feature Selection')\n",
    "plt.xlabel(\"Number of K-Best Features\")\n",
    "plt.ylabel(\"F1 - Score\")\n",
    "plt.grid()\n",
    "\n",
    "num_feat_arr = []\n",
    "for name, model, c in models:\n",
    "    \n",
    "    scores = [0, 0]\n",
    "    results = []\n",
    "\n",
    "    for n in range(2,feat_range):\n",
    "\n",
    "        selection = SelectKBest(k=n).fit(X_train,y_train)\n",
    "        X_k = selection.transform(X_train)\n",
    "        \n",
    "        \n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_k = sc.fit_transform(X_k)\n",
    "        \n",
    "        score = cross_val_score(estimator = model, X = X_k, y = y_train, cv = 10, scoring='f1_micro')\n",
    "        f1 = score.mean()\n",
    "        \n",
    "        results.append(f1)\n",
    "        \n",
    "        std = score.std()\n",
    "        if scores[0] < f1:\n",
    "            scores = [f1, n]\n",
    "  \n",
    "    plt.plot(n_number, results, 'o-', color=c, label=name)\n",
    "    \n",
    "    num_feat_arr.append(scores[1])\n",
    "    max_avg = np.average(scores)\n",
    "    \n",
    "    print(\"Model: %s, Avg_Score: %.3f, Num_Feat: %d\" % (name, scores[0], scores[1]))  \n",
    "\n",
    "\n",
    "plt.axis([0, feat_range , 0.45, 0.70])\n",
    "plt.legend(bbox_to_anchor=(0, 1), loc='upper left', ncol=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5831495880236741\n",
      "{'learning_rate': 0.09000000000000001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier = XGBClassifier(n_jobs=-1, n_estimators=200)\n",
    "\n",
    "n_estimators = np.arange(100,1000,100)\n",
    "max_depth = np.arange(2,5,1)\n",
    "learning_rate = np.arange(0.05,0.15,0.02)\n",
    "\n",
    "parameters = [{\n",
    "    'learning_rate':learning_rate\n",
    "               }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring='f1_micro',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_f1 = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_f1)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585470581408843\n",
      "{'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=400)\n",
    "\n",
    "n_estimators = (150,400,50)\n",
    "max_features = ('auto','sqrt','log2',None)\n",
    "criterion = ('gini','entropy')\n",
    "parameters = [{\n",
    "    'criterion':criterion,\n",
    "               }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring='f1_micro',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_f1 = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_f1)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on unseen data: 0.596\n"
     ]
    }
   ],
   "source": [
    "# Test Performance\n",
    "\n",
    "test_model = RandomForestClassifier(n_estimators=400)\n",
    "test_model.fit(X_train, y_train)\n",
    "y_pred = test_model.predict(X_test)\n",
    "# F1\n",
    "print(\"F1 score on unseen data: %.3f\" % f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = test_data[train_data.columns[chi2_test.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=400)\n",
    "classifier.fit(train_feat, train_label)\n",
    "y_pred = classifier.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test_data['ID']\n",
    "submit = pd.DataFrame({'ID': submit})\n",
    "\n",
    "pred = y_pred\n",
    "pred = pd.DataFrame({'Product': y_pred})\n",
    "\n",
    "product = []\n",
    "product = pred.Product\n",
    "product.replace({ \n",
    "    int(0) : 'Non-Customer', \n",
    "    int(1) : 'V-Bag', \n",
    "    int(2) : 'V-Pet', \n",
    "    int(3) : 'V-Auto'},\n",
    "    inplace=True)\n",
    "\n",
    "submit = submit.join(product)\n",
    "submit.to_csv('result.csv', index = False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "categorical_labels = to_categorical(4, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 16)                448       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 1,060\n",
      "Trainable params: 1,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neurons = 16\n",
    "batch_size = 512         \n",
    "epochs = 500\n",
    "output_size = 4\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "learning_rate = 0.0001\n",
    "optimizer= Adam(learning_rate)\n",
    "\n",
    "hidden_layer_activation = 'tanh'\n",
    "\n",
    "# Build a simple network\n",
    "neural_network = Sequential()\n",
    "neural_network.add(Dense(neurons, input_shape=(X_train.shape[1],),activation=hidden_layer_activation))\n",
    "neural_network.add(Dropout(0.25))\n",
    "neural_network.add(Dense(neurons, activation=hidden_layer_activation))\n",
    "neural_network.add(Dense(neurons, activation=hidden_layer_activation))\n",
    "neural_network.add(Dropout(0.25))\n",
    "neural_network.add(Dense(units=output_size, activation=('softmax')))\n",
    "# Compile the network\n",
    "neural_network.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8617 samples, validate on 950 samples\n",
      "Epoch 1/500\n",
      "8617/8617 [==============================] - 2s 226us/step - loss: 1.4505 - acc: 0.2475 - val_loss: 1.3152 - val_acc: 0.1737\n",
      "Epoch 2/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.4223 - acc: 0.2709 - val_loss: 1.2868 - val_acc: 0.1789\n",
      "Epoch 3/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.3933 - acc: 0.2970 - val_loss: 1.2615 - val_acc: 0.1811\n",
      "Epoch 4/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.3656 - acc: 0.3245 - val_loss: 1.2394 - val_acc: 0.5716\n",
      "Epoch 5/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.3583 - acc: 0.3446 - val_loss: 1.2200 - val_acc: 0.5726\n",
      "Epoch 6/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.3357 - acc: 0.3745 - val_loss: 1.2037 - val_acc: 0.5726\n",
      "Epoch 7/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.3120 - acc: 0.4032 - val_loss: 1.1895 - val_acc: 0.5737\n",
      "Epoch 8/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.3001 - acc: 0.4224 - val_loss: 1.1776 - val_acc: 0.5737\n",
      "Epoch 9/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2859 - acc: 0.4355 - val_loss: 1.1680 - val_acc: 0.5737\n",
      "Epoch 10/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2785 - acc: 0.4538 - val_loss: 1.1598 - val_acc: 0.5737\n",
      "Epoch 11/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2807 - acc: 0.4619 - val_loss: 1.1531 - val_acc: 0.5737\n",
      "Epoch 12/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2743 - acc: 0.4717 - val_loss: 1.1478 - val_acc: 0.5737\n",
      "Epoch 13/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2575 - acc: 0.4791 - val_loss: 1.1437 - val_acc: 0.5747\n",
      "Epoch 14/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.2515 - acc: 0.5019 - val_loss: 1.1403 - val_acc: 0.5737\n",
      "Epoch 15/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2516 - acc: 0.5015 - val_loss: 1.1378 - val_acc: 0.5737\n",
      "Epoch 16/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.2510 - acc: 0.5027 - val_loss: 1.1357 - val_acc: 0.5737\n",
      "Epoch 17/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.2368 - acc: 0.5182 - val_loss: 1.1342 - val_acc: 0.5737\n",
      "Epoch 18/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2403 - acc: 0.5125 - val_loss: 1.1332 - val_acc: 0.5737\n",
      "Epoch 19/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2315 - acc: 0.5198 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 20/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2172 - acc: 0.5243 - val_loss: 1.1319 - val_acc: 0.5737\n",
      "Epoch 21/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2240 - acc: 0.5228 - val_loss: 1.1316 - val_acc: 0.5737\n",
      "Epoch 22/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2239 - acc: 0.5247 - val_loss: 1.1314 - val_acc: 0.5737\n",
      "Epoch 23/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2259 - acc: 0.5259 - val_loss: 1.1311 - val_acc: 0.5737\n",
      "Epoch 24/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2275 - acc: 0.5287 - val_loss: 1.1310 - val_acc: 0.5737\n",
      "Epoch 25/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.2232 - acc: 0.5303 - val_loss: 1.1309 - val_acc: 0.5737\n",
      "Epoch 26/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2148 - acc: 0.5298 - val_loss: 1.1310 - val_acc: 0.5737\n",
      "Epoch 27/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2189 - acc: 0.5335 - val_loss: 1.1310 - val_acc: 0.5737\n",
      "Epoch 28/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2199 - acc: 0.5330 - val_loss: 1.1310 - val_acc: 0.5737\n",
      "Epoch 29/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2104 - acc: 0.5360 - val_loss: 1.1312 - val_acc: 0.5737\n",
      "Epoch 30/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.2133 - acc: 0.5349 - val_loss: 1.1313 - val_acc: 0.5737\n",
      "Epoch 31/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2147 - acc: 0.5355 - val_loss: 1.1315 - val_acc: 0.5737\n",
      "Epoch 32/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2132 - acc: 0.5379 - val_loss: 1.1315 - val_acc: 0.5737\n",
      "Epoch 33/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2184 - acc: 0.5397 - val_loss: 1.1318 - val_acc: 0.5737\n",
      "Epoch 34/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.2080 - acc: 0.5426 - val_loss: 1.1318 - val_acc: 0.5737\n",
      "Epoch 35/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.2127 - acc: 0.5404 - val_loss: 1.1317 - val_acc: 0.5737\n",
      "Epoch 36/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2087 - acc: 0.5381 - val_loss: 1.1318 - val_acc: 0.5737\n",
      "Epoch 37/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2075 - acc: 0.5409 - val_loss: 1.1319 - val_acc: 0.5737\n",
      "Epoch 38/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2042 - acc: 0.5435 - val_loss: 1.1319 - val_acc: 0.5737\n",
      "Epoch 39/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.2030 - acc: 0.5431 - val_loss: 1.1319 - val_acc: 0.5737\n",
      "Epoch 40/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.2048 - acc: 0.5454 - val_loss: 1.1320 - val_acc: 0.5737\n",
      "Epoch 41/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1948 - acc: 0.5430 - val_loss: 1.1320 - val_acc: 0.5737\n",
      "Epoch 42/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.2024 - acc: 0.5460 - val_loss: 1.1322 - val_acc: 0.5737\n",
      "Epoch 43/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.1934 - acc: 0.5447 - val_loss: 1.1322 - val_acc: 0.5737\n",
      "Epoch 44/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2017 - acc: 0.5445 - val_loss: 1.1323 - val_acc: 0.5737\n",
      "Epoch 45/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.2027 - acc: 0.5455 - val_loss: 1.1324 - val_acc: 0.5737\n",
      "Epoch 46/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1979 - acc: 0.5462 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 47/500\n",
      "8617/8617 [==============================] - 0s 29us/step - loss: 1.1978 - acc: 0.5485 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 48/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1951 - acc: 0.5469 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 49/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1978 - acc: 0.5469 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 50/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1934 - acc: 0.5474 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 51/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1961 - acc: 0.5478 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 52/500\n",
      "8617/8617 [==============================] - 0s 27us/step - loss: 1.1936 - acc: 0.5478 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 53/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1900 - acc: 0.5462 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 54/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1952 - acc: 0.5512 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 55/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1932 - acc: 0.5493 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 56/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1951 - acc: 0.5517 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 57/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1908 - acc: 0.5500 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 58/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1877 - acc: 0.5505 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 59/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1892 - acc: 0.5532 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 60/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.1944 - acc: 0.5494 - val_loss: 1.1323 - val_acc: 0.5737\n",
      "Epoch 61/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1931 - acc: 0.5497 - val_loss: 1.1324 - val_acc: 0.5737\n",
      "Epoch 62/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1911 - acc: 0.5495 - val_loss: 1.1324 - val_acc: 0.5737\n",
      "Epoch 63/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1904 - acc: 0.5501 - val_loss: 1.1324 - val_acc: 0.5737\n",
      "Epoch 64/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1881 - acc: 0.5518 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 65/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1856 - acc: 0.5530 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 66/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1934 - acc: 0.5538 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 67/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1946 - acc: 0.5529 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 68/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1902 - acc: 0.5534 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 69/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.1902 - acc: 0.5519 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 70/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1864 - acc: 0.5522 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 71/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1820 - acc: 0.5553 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 72/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1855 - acc: 0.5533 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 73/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1862 - acc: 0.5556 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 74/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1848 - acc: 0.5524 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 75/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1839 - acc: 0.5529 - val_loss: 1.1327 - val_acc: 0.5737\n",
      "Epoch 76/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1808 - acc: 0.5558 - val_loss: 1.1327 - val_acc: 0.5737\n",
      "Epoch 77/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.1871 - acc: 0.5545 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 78/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1801 - acc: 0.5541 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 79/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1827 - acc: 0.5575 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 80/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.1844 - acc: 0.5574 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 81/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1802 - acc: 0.5544 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 82/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.1848 - acc: 0.5554 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 83/500\n",
      "8617/8617 [==============================] - 0s 23us/step - loss: 1.1856 - acc: 0.5559 - val_loss: 1.1326 - val_acc: 0.5737\n",
      "Epoch 84/500\n",
      "8617/8617 [==============================] - 0s 24us/step - loss: 1.1819 - acc: 0.5548 - val_loss: 1.1325 - val_acc: 0.5737\n",
      "Epoch 85/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1832 - acc: 0.5555 - val_loss: 1.1324 - val_acc: 0.5737\n",
      "Epoch 86/500\n",
      "8617/8617 [==============================] - 0s 26us/step - loss: 1.1792 - acc: 0.5576 - val_loss: 1.1324 - val_acc: 0.5737\n",
      "Epoch 87/500\n",
      "8617/8617 [==============================] - 0s 25us/step - loss: 1.1820 - acc: 0.5552 - val_loss: 1.1324 - val_acc: 0.5737\n",
      "Epoch 88/500\n",
      "3072/8617 [=========>....................] - ETA: 0s - loss: 1.1854 - acc: 0.5521"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-e3c2179064df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mneural_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neural_network.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
