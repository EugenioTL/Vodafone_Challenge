{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Import evaluation libraries\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = 202\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train set and test set\n",
    "train_data = pd.read_csv(\"final_train.csv\", delimiter=\",\")\n",
    "test_data = pd.read_csv(\"final_test.csv\", delimiter=\",\")\n",
    "\n",
    "# Drop the ID column\n",
    "train_data = train_data.drop('ID', axis=1)\n",
    "\n",
    "# Sort the dataset\n",
    "train_data = train_data.iloc[np.random.permutation(len(train_data))]\n",
    "train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.asarray(train_data)\n",
    "\n",
    "# X,Y are the splits between features and labels used to evaluate SelectKBest\n",
    "X = array[:,0:train_data.shape[1]-1]\n",
    "X = np.asarray(X)\n",
    "Y = array[:,train_data.shape[1]-1]\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "# Evaluate the features with a chi2 test by using SelectKBest\n",
    "# It must be at most max_feature_number - 1\n",
    "feature_number = 29\n",
    "\n",
    "chi2_test = SelectKBest(score_func=chi2, k=feature_number)\n",
    "fit = chi2_test.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_split(data):\n",
    "    \n",
    "    features = data[train_data.columns[chi2_test.get_support(indices=True)]]\n",
    "    labels = data['Product']\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(features):\n",
    "\n",
    "    scaler = MinMaxScaler().fit(features)\n",
    "    features = scaler.transform(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(features, labels, val_samples, test_samples):\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    features = standardize_features(features)\n",
    "    labels =np.asarray(labels)\n",
    "    \n",
    "    X_test = features[0:test_samples]\n",
    "    y_test = labels[0:test_samples]\n",
    "\n",
    "    X_val = features[test_samples:test_samples + val_samples]\n",
    "    y_val = labels[test_samples:test_samples + val_samples]\n",
    "\n",
    "    X_train = features[test_samples + val_samples:]\n",
    "    y_train = labels[test_samples + val_samples:]\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat, train_label = features_labels_split(train_data)\n",
    "train_label = keras.utils.to_categorical(train_label, 4)\n",
    "\n",
    "num_val_samples = 950\n",
    "num_test_samples = 950\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = train_test_validation_split(train_feat, train_label, num_val_samples, num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7667, 29)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='Graph', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "neurons = 64\n",
    "dropout = 0.3\n",
    "batch_size = 64         \n",
    "epochs = 5000\n",
    "\n",
    "\n",
    "output_activation_function = 'softmax'\n",
    "activation_function = 'relu'\n",
    "\n",
    "loss = 'categorical_crossentropy'\n",
    "learning_rate = 0.0025\n",
    "optimizer= Adam(learning_rate)\n",
    "\n",
    "def build_model(inputs, output_size, neurons, activ_func=activation_function,\n",
    "                dropout = dropout, loss=loss, optimizer=optimizer):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Activation(activation_function))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(neurons))\n",
    "    model.add(Activation(activation_function))\n",
    "    model.add(Dense(units=output_size, activation=output_activation_function))    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 6,340\n",
      "Trainable params: 6,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialise model architecture\n",
    "output_size = 4\n",
    "\n",
    "model = build_model(X_train, output_size=output_size, neurons=neurons)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7667 samples, validate on 950 samples\n",
      "Epoch 1/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8643 - f1: 0.6215 - val_loss: 1.1287 - val_f1: 0.5670\n",
      "Epoch 2/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8507 - f1: 0.6305 - val_loss: 1.1337 - val_f1: 0.5747\n",
      "Epoch 3/5000\n",
      "7667/7667 [==============================] - 1s 82us/step - loss: 0.8579 - f1: 0.6313 - val_loss: 1.1272 - val_f1: 0.5880\n",
      "Epoch 4/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8603 - f1: 0.6277 - val_loss: 1.1334 - val_f1: 0.5740\n",
      "Epoch 5/5000\n",
      "7667/7667 [==============================] - 1s 80us/step - loss: 0.8546 - f1: 0.6290 - val_loss: 1.1252 - val_f1: 0.5802\n",
      "Epoch 6/5000\n",
      "7667/7667 [==============================] - 1s 83us/step - loss: 0.8597 - f1: 0.6231 - val_loss: 1.1277 - val_f1: 0.5752\n",
      "Epoch 7/5000\n",
      "7667/7667 [==============================] - 1s 81us/step - loss: 0.8568 - f1: 0.6296 - val_loss: 1.1261 - val_f1: 0.5769\n",
      "Epoch 8/5000\n",
      "7667/7667 [==============================] - 1s 81us/step - loss: 0.8558 - f1: 0.6315 - val_loss: 1.1302 - val_f1: 0.5748\n",
      "Epoch 9/5000\n",
      "7667/7667 [==============================] - 1s 89us/step - loss: 0.8575 - f1: 0.6287 - val_loss: 1.1378 - val_f1: 0.5762\n",
      "Epoch 10/5000\n",
      "7667/7667 [==============================] - 1s 85us/step - loss: 0.8542 - f1: 0.6259 - val_loss: 1.1450 - val_f1: 0.5726\n",
      "Epoch 11/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8454 - f1: 0.6291 - val_loss: 1.1348 - val_f1: 0.5675\n",
      "Epoch 12/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8506 - f1: 0.6282 - val_loss: 1.1396 - val_f1: 0.5766\n",
      "Epoch 13/5000\n",
      "7667/7667 [==============================] - 1s 79us/step - loss: 0.8478 - f1: 0.6316 - val_loss: 1.1404 - val_f1: 0.5841\n",
      "Epoch 14/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8611 - f1: 0.6216 - val_loss: 1.1462 - val_f1: 0.5759\n",
      "Epoch 15/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8576 - f1: 0.6335 - val_loss: 1.1518 - val_f1: 0.5755\n",
      "Epoch 16/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8491 - f1: 0.6330 - val_loss: 1.1541 - val_f1: 0.5710\n",
      "Epoch 17/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8434 - f1: 0.6380 - val_loss: 1.1524 - val_f1: 0.5803\n",
      "Epoch 18/5000\n",
      "7667/7667 [==============================] - 1s 79us/step - loss: 0.8503 - f1: 0.6254 - val_loss: 1.1473 - val_f1: 0.5682\n",
      "Epoch 19/5000\n",
      "7667/7667 [==============================] - 1s 81us/step - loss: 0.8513 - f1: 0.6287 - val_loss: 1.1420 - val_f1: 0.5763\n",
      "Epoch 20/5000\n",
      "7667/7667 [==============================] - 1s 79us/step - loss: 0.8461 - f1: 0.6328 - val_loss: 1.1516 - val_f1: 0.5681\n",
      "Epoch 21/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8466 - f1: 0.6333 - val_loss: 1.1374 - val_f1: 0.5720\n",
      "Epoch 22/5000\n",
      "7667/7667 [==============================] - 1s 76us/step - loss: 0.8491 - f1: 0.6338 - val_loss: 1.1353 - val_f1: 0.5719\n",
      "Epoch 23/5000\n",
      "7667/7667 [==============================] - 1s 79us/step - loss: 0.8418 - f1: 0.6346 - val_loss: 1.1413 - val_f1: 0.5747\n",
      "Epoch 24/5000\n",
      "7667/7667 [==============================] - 1s 81us/step - loss: 0.8540 - f1: 0.6331 - val_loss: 1.1559 - val_f1: 0.5670\n",
      "Epoch 25/5000\n",
      "7667/7667 [==============================] - 1s 80us/step - loss: 0.8480 - f1: 0.6326 - val_loss: 1.1461 - val_f1: 0.5746\n",
      "Epoch 26/5000\n",
      "7667/7667 [==============================] - 1s 80us/step - loss: 0.8486 - f1: 0.6335 - val_loss: 1.1547 - val_f1: 0.5728\n",
      "Epoch 27/5000\n",
      "7667/7667 [==============================] - 1s 82us/step - loss: 0.8506 - f1: 0.6301 - val_loss: 1.1547 - val_f1: 0.5777\n",
      "Epoch 28/5000\n",
      "7667/7667 [==============================] - 1s 82us/step - loss: 0.8402 - f1: 0.6340 - val_loss: 1.1438 - val_f1: 0.5762\n",
      "Epoch 29/5000\n",
      "7667/7667 [==============================] - 1s 81us/step - loss: 0.8410 - f1: 0.6367 - val_loss: 1.1448 - val_f1: 0.5749\n",
      "Epoch 30/5000\n",
      "7667/7667 [==============================] - 1s 86us/step - loss: 0.8448 - f1: 0.6293 - val_loss: 1.1570 - val_f1: 0.5741\n",
      "Epoch 31/5000\n",
      "7667/7667 [==============================] - 1s 76us/step - loss: 0.8565 - f1: 0.6288 - val_loss: 1.1525 - val_f1: 0.5800\n",
      "Epoch 32/5000\n",
      "7667/7667 [==============================] - 1s 80us/step - loss: 0.8419 - f1: 0.6351 - val_loss: 1.1528 - val_f1: 0.5777\n",
      "Epoch 33/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8502 - f1: 0.6323 - val_loss: 1.1334 - val_f1: 0.5827\n",
      "Epoch 34/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8484 - f1: 0.6324 - val_loss: 1.1472 - val_f1: 0.5659\n",
      "Epoch 35/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8444 - f1: 0.6354 - val_loss: 1.1467 - val_f1: 0.5685\n",
      "Epoch 36/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8494 - f1: 0.6359 - val_loss: 1.1579 - val_f1: 0.5779\n",
      "Epoch 37/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8371 - f1: 0.6359 - val_loss: 1.1634 - val_f1: 0.5784\n",
      "Epoch 38/5000\n",
      "7667/7667 [==============================] - 1s 80us/step - loss: 0.8454 - f1: 0.6339 - val_loss: 1.1602 - val_f1: 0.5844\n",
      "Epoch 39/5000\n",
      "7667/7667 [==============================] - 1s 76us/step - loss: 0.8432 - f1: 0.6336 - val_loss: 1.1685 - val_f1: 0.5739\n",
      "Epoch 40/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8469 - f1: 0.6323 - val_loss: 1.1525 - val_f1: 0.5736\n",
      "Epoch 41/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8393 - f1: 0.6343 - val_loss: 1.1595 - val_f1: 0.5771\n",
      "Epoch 42/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8398 - f1: 0.6405 - val_loss: 1.1465 - val_f1: 0.5739\n",
      "Epoch 43/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8401 - f1: 0.6364 - val_loss: 1.1786 - val_f1: 0.5685\n",
      "Epoch 44/5000\n",
      "7667/7667 [==============================] - 1s 91us/step - loss: 0.8373 - f1: 0.6395 - val_loss: 1.1638 - val_f1: 0.5702\n",
      "Epoch 45/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8404 - f1: 0.6365 - val_loss: 1.1751 - val_f1: 0.5706\n",
      "Epoch 46/5000\n",
      "7667/7667 [==============================] - 1s 86us/step - loss: 0.8484 - f1: 0.6334 - val_loss: 1.1610 - val_f1: 0.5735\n",
      "Epoch 47/5000\n",
      "7667/7667 [==============================] - 1s 84us/step - loss: 0.8471 - f1: 0.6322 - val_loss: 1.1603 - val_f1: 0.5746\n",
      "Epoch 48/5000\n",
      "7667/7667 [==============================] - 1s 87us/step - loss: 0.8465 - f1: 0.6318 - val_loss: 1.1692 - val_f1: 0.5652\n",
      "Epoch 49/5000\n",
      "7667/7667 [==============================] - 1s 74us/step - loss: 0.8287 - f1: 0.6426 - val_loss: 1.1658 - val_f1: 0.5740\n",
      "Epoch 50/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8372 - f1: 0.6371 - val_loss: 1.1527 - val_f1: 0.5755\n",
      "Epoch 51/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8452 - f1: 0.6358 - val_loss: 1.1697 - val_f1: 0.5763\n",
      "Epoch 52/5000\n",
      "7667/7667 [==============================] - 1s 80us/step - loss: 0.8451 - f1: 0.6379 - val_loss: 1.1554 - val_f1: 0.5795\n",
      "Epoch 53/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8427 - f1: 0.6371 - val_loss: 1.1684 - val_f1: 0.5747\n",
      "Epoch 54/5000\n",
      "7667/7667 [==============================] - 1s 74us/step - loss: 0.8322 - f1: 0.6380 - val_loss: 1.1713 - val_f1: 0.5723\n",
      "Epoch 55/5000\n",
      "7667/7667 [==============================] - 1s 83us/step - loss: 0.8387 - f1: 0.6381 - val_loss: 1.1694 - val_f1: 0.5787\n",
      "Epoch 56/5000\n",
      "7667/7667 [==============================] - 1s 85us/step - loss: 0.8417 - f1: 0.6342 - val_loss: 1.1774 - val_f1: 0.5779\n",
      "Epoch 57/5000\n",
      "7667/7667 [==============================] - 1s 91us/step - loss: 0.8352 - f1: 0.6418 - val_loss: 1.1737 - val_f1: 0.5772\n",
      "Epoch 58/5000\n",
      "7667/7667 [==============================] - 1s 82us/step - loss: 0.8497 - f1: 0.6341 - val_loss: 1.1498 - val_f1: 0.5773\n",
      "Epoch 59/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8346 - f1: 0.6408 - val_loss: 1.1592 - val_f1: 0.5736\n",
      "Epoch 60/5000\n",
      "7667/7667 [==============================] - 1s 94us/step - loss: 0.8504 - f1: 0.6338 - val_loss: 1.1762 - val_f1: 0.5671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/5000\n",
      "7667/7667 [==============================] - 1s 91us/step - loss: 0.8366 - f1: 0.6408 - val_loss: 1.1674 - val_f1: 0.5788\n",
      "Epoch 62/5000\n",
      "7667/7667 [==============================] - 1s 88us/step - loss: 0.8389 - f1: 0.6364 - val_loss: 1.1765 - val_f1: 0.5686\n",
      "Epoch 63/5000\n",
      "7667/7667 [==============================] - 1s 82us/step - loss: 0.8410 - f1: 0.6334 - val_loss: 1.1661 - val_f1: 0.5742\n",
      "Epoch 64/5000\n",
      "7667/7667 [==============================] - 1s 84us/step - loss: 0.8335 - f1: 0.6355 - val_loss: 1.1615 - val_f1: 0.5737\n",
      "Epoch 65/5000\n",
      "7667/7667 [==============================] - 1s 77us/step - loss: 0.8358 - f1: 0.6416 - val_loss: 1.1617 - val_f1: 0.5687\n",
      "Epoch 66/5000\n",
      "7667/7667 [==============================] - 1s 76us/step - loss: 0.8427 - f1: 0.6360 - val_loss: 1.1659 - val_f1: 0.5727\n",
      "Epoch 67/5000\n",
      "7667/7667 [==============================] - 1s 74us/step - loss: 0.8342 - f1: 0.6400 - val_loss: 1.1676 - val_f1: 0.5756\n",
      "Epoch 68/5000\n",
      "7667/7667 [==============================] - 1s 74us/step - loss: 0.8374 - f1: 0.6392 - val_loss: 1.1753 - val_f1: 0.5738\n",
      "Epoch 69/5000\n",
      "7667/7667 [==============================] - 1s 76us/step - loss: 0.8348 - f1: 0.6407 - val_loss: 1.1729 - val_f1: 0.5755\n",
      "Epoch 70/5000\n",
      "7667/7667 [==============================] - 1s 74us/step - loss: 0.8352 - f1: 0.6387 - val_loss: 1.1690 - val_f1: 0.5714\n",
      "Epoch 71/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8297 - f1: 0.6446 - val_loss: 1.1722 - val_f1: 0.5727\n",
      "Epoch 72/5000\n",
      "7667/7667 [==============================] - 1s 72us/step - loss: 0.8402 - f1: 0.6407 - val_loss: 1.1614 - val_f1: 0.5730\n",
      "Epoch 73/5000\n",
      "7667/7667 [==============================] - 1s 75us/step - loss: 0.8309 - f1: 0.6446 - val_loss: 1.1744 - val_f1: 0.5770\n",
      "Epoch 74/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8378 - f1: 0.6392 - val_loss: 1.1626 - val_f1: 0.5794\n",
      "Epoch 75/5000\n",
      "7667/7667 [==============================] - 1s 74us/step - loss: 0.8275 - f1: 0.6457 - val_loss: 1.1730 - val_f1: 0.5813\n",
      "Epoch 76/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8285 - f1: 0.6449 - val_loss: 1.1790 - val_f1: 0.5808\n",
      "Epoch 77/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8274 - f1: 0.6415 - val_loss: 1.1732 - val_f1: 0.5688\n",
      "Epoch 78/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8394 - f1: 0.6392 - val_loss: 1.1873 - val_f1: 0.5739\n",
      "Epoch 79/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8316 - f1: 0.6430 - val_loss: 1.1834 - val_f1: 0.5694\n",
      "Epoch 80/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8357 - f1: 0.6424 - val_loss: 1.1802 - val_f1: 0.5672\n",
      "Epoch 81/5000\n",
      "7667/7667 [==============================] - 1s 74us/step - loss: 0.8363 - f1: 0.6443 - val_loss: 1.1801 - val_f1: 0.5656\n",
      "Epoch 82/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8322 - f1: 0.6380 - val_loss: 1.1748 - val_f1: 0.5772\n",
      "Epoch 83/5000\n",
      "7667/7667 [==============================] - 1s 80us/step - loss: 0.8249 - f1: 0.6454 - val_loss: 1.1755 - val_f1: 0.5766\n",
      "Epoch 84/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8434 - f1: 0.6315 - val_loss: 1.1673 - val_f1: 0.5762\n",
      "Epoch 85/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8319 - f1: 0.6431 - val_loss: 1.1740 - val_f1: 0.5839\n",
      "Epoch 86/5000\n",
      "7667/7667 [==============================] - 1s 73us/step - loss: 0.8303 - f1: 0.6410 - val_loss: 1.1653 - val_f1: 0.5767\n",
      "Epoch 87/5000\n",
      "7667/7667 [==============================] - 1s 88us/step - loss: 0.8390 - f1: 0.6353 - val_loss: 1.1631 - val_f1: 0.5760\n",
      "Epoch 88/5000\n",
      "7667/7667 [==============================] - 1s 87us/step - loss: 0.8340 - f1: 0.6433 - val_loss: 1.1648 - val_f1: 0.5741\n",
      "Epoch 89/5000\n",
      "7667/7667 [==============================] - 1s 88us/step - loss: 0.8297 - f1: 0.6402 - val_loss: 1.1761 - val_f1: 0.5744\n",
      "Epoch 90/5000\n",
      "7667/7667 [==============================] - 1s 82us/step - loss: 0.8249 - f1: 0.6450 - val_loss: 1.1883 - val_f1: 0.5696\n",
      "Epoch 91/5000\n",
      "7667/7667 [==============================] - 1s 87us/step - loss: 0.8267 - f1: 0.6450 - val_loss: 1.1897 - val_f1: 0.5608\n",
      "Epoch 92/5000\n",
      "7667/7667 [==============================] - 1s 87us/step - loss: 0.8334 - f1: 0.6391 - val_loss: 1.1885 - val_f1: 0.5634\n",
      "Epoch 93/5000\n",
      "7667/7667 [==============================] - 1s 90us/step - loss: 0.8274 - f1: 0.6415 - val_loss: 1.1969 - val_f1: 0.5634\n",
      "Epoch 94/5000\n",
      "7667/7667 [==============================] - 1s 87us/step - loss: 0.8324 - f1: 0.6375 - val_loss: 1.1880 - val_f1: 0.5622\n",
      "Epoch 95/5000\n",
      "7667/7667 [==============================] - 1s 78us/step - loss: 0.8317 - f1: 0.6411 - val_loss: 1.1824 - val_f1: 0.5666\n",
      "Epoch 96/5000\n",
      "7667/7667 [==============================] - 1s 86us/step - loss: 0.8272 - f1: 0.6394 - val_loss: 1.1732 - val_f1: 0.5698\n",
      "Epoch 97/5000\n",
      "3584/7667 [=============>................] - ETA: 0s - loss: 0.8203 - f1: 0.6439"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-98f63b85b0ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                             callbacks=[tensorboard], shuffle=False)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\eugen\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model on data\n",
    "history = model.fit(X_train, y_train,\n",
    "                            epochs=epochs, batch_size=batch_size,\n",
    "                            verbose=1, validation_data=(X_val, y_val),\n",
    "                            callbacks=[tensorboard], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
